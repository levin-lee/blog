<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>风控策略之准入</title>
    <url>/2020/05/04/%E9%A3%8E%E6%8E%A7%E7%AD%96%E7%95%A5%E4%B9%8B%E5%87%86%E5%85%A5/</url>
    <content><![CDATA[<p>现代金融体系，由银行、证券、保险、基金、信托等几大行业所组成。其中银行是金融体系的基石，连接实业和金融，调节货币供给。其中风险管理又是银行中最为重要的一环。<br>科技赋能金融，是这个时代的主流。风险管理，是金融发展的必选命题。在当代，金融机构在风险管理的每个环节都尽可能地引入计量分析方法，依托大数据进行数据分析，不断迭代优化调整，使得金融机构在风险与收益的博弈过程中更快达到平衡，实现利润的最大化。风控策略，则是金融机构追求利润最大化的强大武器。风控策略，广义上是代表一种风险管理战略思想，狭义上讲，是一个个数据规则组合而成的风险管理架构。<br><a id="more"></a><br>目录<br>一、风控策略概要<br>二、风控策略分析师<br>三、规则所需数据的主流获取方式<br>四、策略分析常见工作场景与对应分析方法<br>三方数据源测评<br>准入策略的制定<br>白名单策略<br>黑名单策略<br>规则阈值cutoff如何设定<br>通过率下降的策略调整<br>逾期率上升的策略调整<br>信用多头策略<br>评分的策略应用<br>五.模型与策略的楚河汉界</p>
<h1 id="01-风控策略概要"><a href="#01-风控策略概要" class="headerlink" title="-01-风控策略概要"></a>-01-风控策略概要</h1><h2 id="一、什么是风控审批策略？"><a href="#一、什么是风控审批策略？" class="headerlink" title="一、什么是风控审批策略？"></a>一、什么是风控审批策略？</h2><p>是基于数据分析在申请、交易、复购等阶段制定各式各样多维度的策略和规则，其中多维度数据的策略规则包括：<br>运营商规则（手机入网时长、月均消费费用、通话时长、短信数量、手机联系人等）<br>移动设备维度规则（设备关联账号、IP地址、LBS地址信息、GPS地址、SIM卡、wifi、指纹等）<br>征信规则（资产、负债、征信白户、征信不良、信用卡使用记录、历史借贷、历史逾期情况等）<br>黑名单规则（手机黑名单、身份证黑名单、地址黑名单、公司黑名单、联系人黑名单、银行卡黑名单等）<br>账号行为规则(账号关联设备、注册时间、登陆时间、绑定身份证、绑定银行卡等)<br>多头规则（外部多头借贷数据、手机借款APP）<br>欺诈规则（个人欺诈：三证齐全、人脸识别；团伙欺诈）</p>
<h2 id="二、风控审批策略的目的"><a href="#二、风控审批策略的目的" class="headerlink" title="二、风控审批策略的目的"></a>二、风控审批策略的目的</h2><p>在贷前审批减少风险事件的发生的各种可能性，挽回风险事件时造成的损失。较大的程度上筛选过滤高风险客户，保留低风险客户予以营销。针对客群分级实行个性化的审批流程，提高审批效率。</p>
<h2 id="三、风控审批策略的作用"><a href="#三、风控审批策略的作用" class="headerlink" title="三、风控审批策略的作用"></a>三、风控审批策略的作用</h2><p>在保证业务量的同时降低业务坏账率、控制逾期风险，最终实现公司盈利。</p>
<h2 id="四、风控审批策略的类别"><a href="#四、风控审批策略的类别" class="headerlink" title="四、风控审批策略的类别"></a>四、风控审批策略的类别</h2><p>多维度数据分析呈现了借款人的用户画像，制定多维度完善的审批策略规则，具体策略规则包含：<br>1）基本信息维度(年龄、性别、学历、城市、常住地址等)<br>2）公司维度（公司名称、职业、行业、工资、公司地址等）<br>3）资产负债维度（车贷、房贷、外部借贷、银行卡流水)<br>4）信用历史（征信贷款信息、还款记录）<br>5）app信息维度(贷款APP安装个数、短信命中高风险关键词)<br>6）行为表现(活动轨迹、登陆时间、注册时间等信息)</p>
<h2 id="五、风控的基本量化指标"><a href="#五、风控的基本量化指标" class="headerlink" title="五、风控的基本量化指标"></a>五、风控的基本量化指标</h2><p>FPDx：首期逾期，x对应天数#CPDx：当前逾期，x对应天数逾期时间的长短来定义逾期的等级，C代表正常资产。<br>M1：逾期1-30天；M2：逾期31-60天；M3：逾期61-90天；M4：逾期91-120天；M5：逾期121-150天；M6：逾期151-180天；不良资产：逾期91天+；损失资产：逾期181+<br>Flow rate：迁徙率释义：前期资产等级，落入下一期的比率。举例：C-M1=M月月末M1资产余额 / 上月末C的在贷余额8月C-M1 ：8月末进入M1的贷款余额 / 7月月末C的贷款余额<br>迁徙率的计算，主要用于分析观察每个月份贷款的催收率，催收人员的催收力度对比，也用于计算公司的坏账计提标准、资产拨备。<br>贷款状态—&gt;迁徙率报表<br>vintage：账龄分析<br>MOB0,放款日至当月月底<br>MOB1,放款后一个月份<br>MOB2,放款后两个月份<br>Vintage Delinquency 31+(MOB3)：放款月后的三个月份,逾期天数31+剩余本金/放款月的贷款总额。</p>
<h2 id="六、确定目标变量根据催回率及迁徙率确定好坏客户"><a href="#六、确定目标变量根据催回率及迁徙率确定好坏客户" class="headerlink" title="六、确定目标变量根据催回率及迁徙率确定好坏客户"></a>六、确定目标变量根据催回率及迁徙率确定好坏客户</h2><h2 id="七、策略预估"><a href="#七、策略预估" class="headerlink" title="七、策略预估"></a>七、策略预估</h2><p>预估策略上线对生产运营阶段的影响，基于进件量、放款量、通过率的影响。</p>
<h2 id="八、策略监控"><a href="#八、策略监控" class="headerlink" title="八、策略监控"></a>八、策略监控</h2><p>策略上线后，监控此策略的占比与预计的占比是否发生严重偏差，且在正常运行阶段是否全部执行。</p>
<h2 id="九、策略回顾"><a href="#九、策略回顾" class="headerlink" title="九、策略回顾"></a>九、策略回顾</h2><p>对上线后的策略，在一定时间后。对于有表现的数据进行策略回顾，看策略调整后的进件量、通过率及贷后表现。若是想及时的查看策略上线后的贷后表现可以针对FPD指标分不同的天数去观测，FPD4，FPD10，FPD30等。<br>若策略是调宽或者是放松时，可以针对性回顾下豁免出来的客户的进件情况、通过率及贷后表现。若策略是调严或者收紧时，可以针对性回顾拒绝阀值边缘维度的贷后表现及拟定拒绝的客户数。</p>
<h1 id="02-风控策略分析师"><a href="#02-风控策略分析师" class="headerlink" title="-02- 风控策略分析师"></a>-02- 风控策略分析师</h1><h2 id="1-日常工作内容"><a href="#1-日常工作内容" class="headerlink" title="1 日常工作内容"></a>1 日常工作内容</h2><p>1）贷前、贷中及贷后各环节的风险策略与流程，制订各项策略规则，具体包括准入、授信、定价、用信、还款、调额等信贷流程各阶段的策略规则；<br>2）通过对各类风险指标与报表的分析，关注各类资产和客群的风险变动，对公司全渠道风险政策与策略进行跟踪评价，并及时优化调整相应的风险政策与策略</p>
<h2 id="2-必备技能"><a href="#2-必备技能" class="headerlink" title="2 必备技能"></a>2 必备技能</h2><p>1）结合内外数据，通过统计分析方法，对不同风险点制定出不同类型的风险规则<br>2）完成整个贷前、贷中和贷后的风险规则架构，实现自动化风控<br>3）可以实现策略规则优化，不限于A、D类调优方法<br>4）规则的部署与监控预警<br>5）临时指标调整的项目经验</p>
<h2 id="3-核心作用"><a href="#3-核心作用" class="headerlink" title="3 核心作用"></a>3 核心作用</h2><p>实现具体规则和流程的设计、开发、部署、监控与优化</p>
<h1 id="03-主流数据获取方式"><a href="#03-主流数据获取方式" class="headerlink" title="-03- 主流数据获取方式"></a>-03- 主流数据获取方式</h1><p>只有数字化基础建设，才能解决获客时对应的数据收集问题，用户生命全周期管理才得以继续开展。下面介绍一些主流数据获取方式。</p>
<h2 id="1-H5渠道"><a href="#1-H5渠道" class="headerlink" title="1) H5渠道"></a>1) H5渠道</h2><p>H5是HTML5的简称，是一种快速开发网页的编程语言。H5渠道就是基于HTML5语言开发或搭建出来的网页，有电脑端和手机移动端两种形态。金融机构获得客户如果采用H5页面方式，一般都是基于自家的微信公众号、小程序进行。H5渠道的优点是开发方便快捷，属于轻量级开发任务。但缺点也明显，风控采数上限制颇多，因为纯H5页面只能搜集类表格型数据，也就是你想让客户填写什么信息，就要在H5页面体现出输入框，以及少量的浏览器和系统信息。更多的数据无法在纯H5渠道上获取。所以，金融机构常常为了保证用户体验要放弃掉更多的客户信息主动填写设定。一般，通过H5渠道主要为了达到如下目的：</p>
<ul>
<li>产品宣传；</li>
<li>基础信息填写；</li>
<li>浏览器版本号、登录时的地理位置、手机系统类型（如安卓、苹果）、是不是虚拟机和越狱；</li>
<li>插件跳转</li>
</ul>
<h2 id="2-API渠道"><a href="#2-API渠道" class="headerlink" title="2) API渠道"></a>2) API渠道</h2><p>API是Application Programming Interface的缩写，是应用程序编写的接口<br>从上述形象的例子可以发现，通过API渠道我们可以从流量平台获取大量的客户信息，理论上我们需求什么，都可以通过API来传。但是API传什么是根据数据提供方的意愿来传，接口可以有这个数据，但是数据合作方也可以选择不传。另外数据的真实性也没办法确认，因为数据是合作机构提供给的，并不是通过自己程序抓取的。API渠道获客的全流程完全在提供API接口的合作方内部完成，自始至终都没有离开他们的平台，甚至可以连提现环节都是在他们平台里实现，这样连提现分佣也都有相关的利益关联。API渠道操作简单，一般只需要完成与合作机构的接口对接即可获得客户及其数据。相比较纯H5可以获得更丰富的客户信息，有更多的维度做用户风险管理，但也因为与合作机构发生关联关系，省事之外，有更多的商务谈判和利益关系。</p>
<h2 id="3-SDK"><a href="#3-SDK" class="headerlink" title="3) SDK"></a>3) SDK</h2><p>在现实社会里，金融机构通过将SDK嵌套在自家的H5或APP里，以实现封闭式数据获取和管理。在风控采数上也更加的灵活，比如可以通过SDK设定，获取用户的设备唯一识别码进行反欺诈、采集用户信贷申请时的行为数据进行信用评分模型建模。风控自建客户数据都可以借助SDK实现。<br>APP和网站</p>
<h1 id="04-策略分析常见工作场景与对应分析方法"><a href="#04-策略分析常见工作场景与对应分析方法" class="headerlink" title="-04- 策略分析常见工作场景与对应分析方法"></a>-04- 策略分析常见工作场景与对应分析方法</h1><h2 id="1-三方数据测评"><a href="#1-三方数据测评" class="headerlink" title="1 三方数据测评"></a>1 三方数据测评</h2><p>案例：现有1000个样本数据，分别测试2家黑名单，2家欺诈名单与2家多头，如何选择合适的第三方数据源？<br>首先要专业科普选择第三方数据源重要考察的5大指标计算公式（以黑名单为例）：<br>查得率(Search rate)=查得数/样本量</p>
<ul>
<li>覆盖率(Cover rate)=查得命中黑名单数/样本中命中黑名单量</li>
<li>误拒率(Error reject rate)=查得命中黑名单数/样本中通过且为Good量</li>
<li>有效差异率(Effective difference rate)=查得命中黑名单数/样本中通过且Bad量</li>
<li>无效差异率(Invalid difference rate)=查得命中黑名单数/样本中其他拒绝量</li>
</ul>
<p>其中SR、CR、EDR指标越高越好，ERR越低越好，IDR与EDR结合起来观察，如果IDR和EDR都较高，反应的一种情况是数据源定义黑名单是广撒网式，黑名单质量相对不够精准。其中前三个指标是重点考察，如果想更全面的测试第三方数据源，后面两个差异率指标也可以加入考核标准。<br>数据介绍：<br>1000个测试样本数据中，审批结果字段表示样本通过和拒绝，其中通过样本中有未逾期和发生逾期的客户样本，拒绝样本中有通过黑名单库拒绝客户，也有其他原因产生拒绝。比如，数据源1（黑名单）代表一家提供黑名单数据的数据供应商A，数据源2（黑名单）代表另一家提供黑名单数据的数据供应商B，以此类推。<br>对1000条测试数据返回结果进行整理可以总结出如上数据概要，对比看到数据源1的返回结果如下：<br>数据源1   数据源2<br>查得总量814个；  查得总量769个；<br>命中黑名单35个； 命中黑名单33个；<br>通过中为Good3个； 通过中为Good4个；<br>通过中为Bad8个；  通过中为Bad12个；<br>其他拒绝为22个；  其他拒绝为62个<br>采用专业考察第三方数据源的五大指标，对以上返回结果计算分析得到以下结果：</p>
<p>按照文章开始介绍的指标分析方法，对比数据源1和数据源2的测试结果可以得出如下结论：<br>1) 数据供应商1的查得率、覆盖率高于数据供应商2大约5%、4%；<br>2) 数据供应商1的误拒率低于数据供应商2大约0.3%；<br>3) 数据供应商1的有效差异率低于数据供应商2大约8%，无效差异率低于数据供应商2大约7%；<br>依据五大指标分析标准，SR、CR、EDR指标越高越好，ERR越低越好，IDR与EDR结合起来观察，如果IDR和EDR都较高，反应的一种情况是数据源定义黑名单是广撒网式，黑名单质量相对不够精准！<br>最终分析结论：<br>数据供应商2虽然覆盖的黑名单比数据供应商1的更广，但其不如数据供应商1精准，更偏向选择数据供应商1的黑名单数据。</p>
<h2 id="2-准入策略的制定"><a href="#2-准入策略的制定" class="headerlink" title="2 准入策略的制定"></a>2 准入策略的制定</h2><p>风控准入策略作为金融借贷机构评估一个借款人是否有机会获得授信的第一道门槛，是借款人与贷款人之间平等合理的发生金融供需关系的基石，也是保卫金融机构的第一道护卫。风控准入策略属于贷前风控策略体系的一部分，贷前风控策略包括基础认证、准入策略，贷前反欺诈策略，黑名单策略，特殊名单策略及信用风险策略。风控准入策略中的规则更多是由产品政策性规则构成。<br>-1- 为什么要设计风控准入策略<br>风控准入策略作为维护贷款人利益的基石，从设计之初就决定了它的重要作用。风控准入策略的规则属性全部为强拒绝规则（硬规则），借款人一旦不满足一条准入规则金融贷款机构都不会给予贷款的授信与发放；同时，风控准入规则不需要经过复杂的规则衍生，通常可以简单有效的判决借款人是否有资格进入之后的风控流程；最后，风控准入规则的策略理念是验证借款人依法合规未被政策限制。<br>-2- 风控准入策略模块<br>在讲风控准入策略模块之前，不得不提风控基础认证模块。基础认证模块主要作用是验证借款此人是本人，也是以风控规则形式出现，规则大多为公允共认的规则。比如身份证信息验证，人脸信息验证、银行卡四要素验证、运营商三要素验证等。在验证完借款人基础信息后，风控贷前流程才会进入准入策略模块。准入策略模块主要分为年龄准入、地区准入、行业准入及其他。这些准入规则的根本设定原则是基于监管和金融机构产品政策性导向。<br>年龄准入策略：其中借款人具有完全民事行为能力的中华人民共和国公民年龄范围在18-60岁。<br>地区准入策略：地区准入规则的初始设定一般是风险集中度比较高、社会稳定性比较弱、地区经济GDP比较低，亦或是难催收的地区，比如新疆、东北等个别地域。<br>行业准入策略：大多金融机构信贷业务都会禁止的行业有金融属性行业如投资、担保、理财、典当；政策性敏感娱乐行业如KTV、按摩院、会所等；无业和自由职业。<br>-3- 风控准入策略的功能与意义<br>风控准入规则，就是如同人体的皮肤和黏膜，是整体风控流程中的第一道防线。虽然现在大部分金融机构的准入策略已经逐渐趋同与固化，风险防范的更多重心在风控流程的反欺诈、黑名单、信用策略等，但在一些具体金融模式和场景下，如消费分期贷、循环现金贷、信用卡、小微企业与个体工商户现金贷，对于准入规则阈值的具体策略仍有差异。<br>针对不同信贷场景采取更适应业务的准入规则，设定科学的准入策略，对于风险的防范与降维有十分重要意义。合理的风险准入策略，也能对信贷业务的走向与风险倾向产生直接影响，进一步影响金融机构的最终盈亏。</p>
<h2 id="3-白名单策略"><a href="#3-白名单策略" class="headerlink" title="3 白名单策略"></a>3 白名单策略</h2><p>金融机构在开展信贷业务的时候，有一批客户是风险相对可知可控，对这批客户进行授信贷款时，金融机构风控工作者内心比较“信任”，由这批客户构成的内部名单，就是业内俗称的“白名单”。<br>风控白名单的定义<br>其实，针对不同的业务场景会有相应的白名单类型，一般业务上经常使用的白名以下两种业务场景：A.在存在自有存量数据的前提下，金融机构想开展信贷业务，前期需要通过白名单控制入口，此类场景多存在于业务初期，或者是内部员工贷的业务场景。B.在业务开展中期，需要部分进件客户走特殊贷前审批流程，满足特殊审批的要求，此类场景多存在于较大的金融公司。分析A场景，可以发现此时的风控白名单可以帮助金融机构在风控模型不完善的条件下，先把业务开展起来。同时，在这个展业的过程中，可以逐渐组建适合金融机构业务的风控策略和模型。对于处于B场景的风控白名单，更像我们认知中的借贷”VIP”，他们有着较好的信用、较好的资产亦或是较好的“背景”，通过一些特殊审批流程进行贷款的审核，最终满足“VIP”的借贷需求。综合来讲，白名单可以定义为，通过金融机构内部现有数据判断的“好客户”，或者经过一系列规则挖掘分析得出的“好客户”，由他们组成的借贷优质名单。<br>如何筛选出白名单<br>白名单即然是由借贷优质“VIP”组成的，那么我们应该通过什么方式筛选出风控白名单呢？在这里提供几种筛选白名单的策略。</p>
<h3 id="1-联合建模"><a href="#1-联合建模" class="headerlink" title="1 联合建模"></a>1 联合建模</h3><p>金融机构在有存量数据的前提下，自有数据是不缺乏X特征变量，主要缺乏相应业务场景有表现特征的目标Y变量。在这个时候可以通过引进一些外部机构进行联合建模，用以补充一些Y变量。通过与外部机构联合建模得出评分，不论是将其用于内部客户分层，还是将评分分数直接做规则，都对筛选白名单有很好的帮助。</p>
<h3 id="2-内部数据探索"><a href="#2-内部数据探索" class="headerlink" title="2 内部数据探索"></a>2 内部数据探索</h3><p>我们在筛选白名单的时候，除了通过联合建模弥补相应业务场景下目标变量的缺失，还可以通过内部数据探索，寻找分析一些对逾期违约表现相关性较强的一些特征规则，逐渐设定出白名单规则。这里面分为两种规则设定方式。第一种是寻找与新开展业务相似模式和场景的已有产品，参照已有产品的风控策略规则对新业务场景数据进行比对分析，参照已有产品的策略规则制定出新业务场景的风控白名单规则。另外一种方式是在更“艰苦”的环境下，没有任何可对比参照的已有产品，这个时候设定的白名单规则相对更严谨，同时对风控策略工作者的业务经验要求更高，可以认为是一种专家经验规则。</p>
<h3 id="3-引入外部数据匹配"><a href="#3-引入外部数据匹配" class="headerlink" title="3 引入外部数据匹配"></a>3 引入外部数据匹配</h3><p>在进行内部数据探索的同时，我们也可以通过引入一些外部数据如工作单位、学历、社保缴费单位、公积金缴费单位、缴费基数等一些对好坏客群区分能力较强的数据，通过内部数据与外部数据的变量结合，共同设定出白名单策略规则，筛选出优质客群。<br>白名单的作用<br>即然白名单是我们业务开展初期或者大型金融机构风控的“特殊”安全线，那究竟白名单在业务场景中有怎样的作用呢？我们以上文提到的A业务场景简单介绍下白名单的作用。</p>
<h3 id="1-控制放量节奏"><a href="#1-控制放量节奏" class="headerlink" title="1 控制放量节奏"></a>1 控制放量节奏</h3><p>从业务发展角度来看，其实白名单只是一个过渡，存量数据一定会有用完的一天，风险管理最终的目标还是开放所有人群进行信贷业务的申请，所以在金融机构新业务开展初期，白名单的作用更多的是可以控制放量的节奏，便于整体调控。</p>
<h3 id="2-降低风险"><a href="#2-降低风险" class="headerlink" title="2 降低风险"></a>2 降低风险</h3><p>即然白名单是我们认为的优质借贷“VIP”，在新业务开展初期对他们进行放款产生违约的风险一定比其他客群的风险更低。</p>
<h3 id="3-提高审批通过率"><a href="#3-提高审批通过率" class="headerlink" title="3 提高审批通过率"></a>3 提高审批通过率</h3><p>对白名单客群，我们的风控规则相对较松，自然在放款初期风险相对可控的前提下，我们有相对较高的审批通过率。在一定意义上，也有利于前期业务的积累，从整个信贷管理周期来讲，也可以认为是一种风控战略。</p>
<h3 id="4-可协助调整贷前策略"><a href="#4-可协助调整贷前策略" class="headerlink" title="4 可协助调整贷前策略"></a>4 可协助调整贷前策略</h3><p>风控白名单的筛选也是由一系列的贷前策略规则组成。在之后的风控策略与模型搭建过程中，通过基于白名单规则的衍生、白名单中逾期客户的策略回顾，也可以协助风控策略人员调整贷前策略。<br>总结可以看到，风控白名单作为一类“特殊”借贷客群，不论对于金融机构新业务快速展业，还是在业务发展中期特殊客群关系贷款，白名单在整体风控策略模型中，都扮演着一份”特殊“的角色，也正是因为这一份特殊性，风控白名单也可以称为风险控制的”特殊安全线”。</p>
<h2 id="4-黑名单策略"><a href="#4-黑名单策略" class="headerlink" title="4 黑名单策略"></a>4 黑名单策略</h2><p>黑名单，顾名思义是性质极其恶劣的坏客户。无论是其还款能力，还款意愿，借款目的等都不能满足正常客户的标准。在金融机构里，黑名单的来源一般有自建和外部引用两种。对于业务初期的金融机构通常调用三方数据接口查询行内黑名单客户，同时在自家展业过程中，通过贷后管理逐渐补充、完善自家黑名单库。</p>
<h3 id="1-黑名单客户为金融机构带来巨大损失"><a href="#1-黑名单客户为金融机构带来巨大损失" class="headerlink" title="-1- 黑名单客户为金融机构带来巨大损失"></a>-1- 黑名单客户为金融机构带来巨大损失</h3><p>假设一个场景：如果有一万块钱，借款一年，不考虑其他，综合年化36%的信贷产品，因为一个黑名单客户导致本金全部损失，那么实际上需要大约3个好客户才能弥补1个坏客户的损失。如果我们加上资金的运营成本，人力成本，引流成本，实际成本等。 假设需要的综合年化是15%，那么实际上 ，也就是5个好客户才能覆盖一个坏客户的本金损失，同时还需要覆盖上述的各种成本 ，也就是说金融机构大约要用6个完全的好人才能替代一个完整的坏人。而在现实情况下，并不是所有的产品都是12期，也会有3期、6期产品，同时也包含资金占有率问题，实际上需要的用更多的好人去覆盖坏客户带来的损失。从上述场景我们可以看到，黑名单对于金融机构的影响以及所付出的代价是巨大的。所以，黑名单库的使用对于金融机构来讲是一项特别重要的工作。</p>
<h3 id="2-黑名单的一般使用方法"><a href="#2-黑名单的一般使用方法" class="headerlink" title="-2-黑名单的一般使用方法"></a>-2-黑名单的一般使用方法</h3><p>正因为黑名单库里的客户一旦贷款成功会对金融机构带来巨大的损失，所以目前金融机构风控部采用的风控策略是黑名单全部拒绝，但是，对于不同业务属性的机构，黑名单的风控策略也不是绝对的。打个比方，对于金融机构业务最核心的问题是本金安全，所以申请客户一旦触碰到黑名单规则，金融机构通常会全部拒绝。但对于导流助贷性质的金融科技机构，业务最核心的问题是流量和客户质量，如果全部拒绝黑名单客群，其所付出的成本巨大。因此导流助贷机构可能会选择性放入一部分客群，结合客户评分，多头等数据综合判断，或者随机放过。</p>
<h3 id="3-黑名单的测试"><a href="#3-黑名单的测试" class="headerlink" title="-3-黑名单的测试"></a>-3-黑名单的测试</h3><p>金融机构一般在全部拒绝黑名单前，会随机放过5%或者10%的触碰黑名单的客户，去测试黑名单数据有“多黑”，测试该黑名单客群是否适用于该机构。</p>
<h3 id="4-黑名单库的自建"><a href="#4-黑名单库的自建" class="headerlink" title="-4-黑名单库的自建"></a>-4-黑名单库的自建</h3><p>黑名单一般的自建维度有参照回款表现、渠道、利率、各种公布失信类客户以及通过爬虫获得的一系列坏客户，黑名单的设定不一定仅限客户本身，也可以拓展为身份证、手机号、邮箱、银行卡、ip地址等，都可作为自建黑名单的参考维度。</p>
<h3 id="5-黑名单的引用"><a href="#5-黑名单的引用" class="headerlink" title="-5-黑名单的引用"></a>-5-黑名单的引用</h3><p>市面上绝大部分三方金融科技公司都有自己的黑名单库服务，这是金融机构主要引用的黑名单库。因为自建黑名单命中率通常不会太高（相同客户再次注册的概率较低），且自建黑名单库需要长期的业务积累过程，因此金融信贷机构常常需要借助三方金融科技公司的黑名单库服务（特指三方数据供应商商以及其他金融信贷机构）。</p>
<h3 id="6-爬虫类数据的对黑名单影响"><a href="#6-爬虫类数据的对黑名单影响" class="headerlink" title="-6-爬虫类数据的对黑名单影响"></a>-6-爬虫类数据的对黑名单影响</h3><p>爬虫是增加数据维度最重要的方式，同时爬虫类数据可以最大程度减少成本的损耗。金融机构查询征信的成本是非常高的，助贷导流客户平均成本一般不会超过5毛钱，金融机构开展信贷业务所需风控数据成本也不会超过10元。现在国家对爬虫类数据开展严查，爬虫类的严格监管再次使得风控成本急剧上升，而目前市场上很多黑名单的生成正是爬虫爬取的数据，最终导致的结果就是黑名单数量开始变少，变相导致风控成本的增加。虽然现在大量p2p以及小贷机构接入百行征信，但我想要说明的是：滞后性和成本的增加使得黑名单需要更多的共享，只有共享才能更全面了解我们金融机构所接触的客群。</p>
<h2 id="5-规则阈值cutoff如何设定"><a href="#5-规则阈值cutoff如何设定" class="headerlink" title="5 规则阈值cutoff如何设定"></a>5 规则阈值cutoff如何设定</h2><p>对于风控策略分析师，如何从大量的规则维度中找到核心风控指标，不仅要基于数据分析结果，同时也要具备风险识别敏感度。风控指标的拒绝线划分，之前被多数人甚至同业者一致认为是“拍脑袋”的决策，这样也让策略分析师有了“玄学”、“经验主义”的另一称号。其实，风险策略拒绝线的设定，背后有严谨的分析逻辑，本文就以评分分数区间和年龄规则为例，为大家讲解审批策略拒绝线的内在分析方法。<br>背景介绍<br>评分模型，尤其是主流基于线性Logistic算法的评分模型，对于一些边际评分区间的风险，其实常常无法精准的预估到，势必会造成一些区间风险被低估的现象。如果不通过一些规则维度的拒绝补充，容易因为模型风险发生不必要的利益损失。<br>假设我们已经对评分模型分数分为T1-T5组，T1风险最低T5风险最大。年龄规则也使用单变量树模型初步分为5组区间。我们希望结合评分分数找到年龄规则这个核心策略维度的合理拒绝线。<br>第一步：通过评分找到风险被低估的区间<br>本例中，首先将年龄与评分卡进行交叉矩阵分析，观测不同交叉区间里的用户违约概率。</p>
<p>上图示例1对于从事策略分析人员应该不会陌生。一般策略规则多数组之间的趋势线是紧密相近的。从图示数据走线可以发现，年龄组[35,47)和[47,53)这两个年龄组的违约概率走线脱离了其他分组，尤其是年龄组[35,47)，其走线脱离其他“群体”过多。通过分析初步定位年龄组[35,47)和[47,53)可以是待确定的规则拒绝线。<br>第二步，评估拟拒绝人群的收益/风险比<br>虽然经过评分与年龄的交叉对比，发现年龄规则的两个待确定高风险拒绝区间。但是实际拒绝线的划分要结合年龄分组区间人群的实际收益与风险进一步考虑。如果高风险的人群可以带来高收益，对于策略来讲也是可以接受的。</p>
<h2 id="6-通过率下降的策略调整"><a href="#6-通过率下降的策略调整" class="headerlink" title="6 通过率下降的策略调整"></a>6 通过率下降的策略调整</h2><p>审批通过率和不良率是一对权衡指标，在新业务上线初期，维持一个较低的通过率可以保证最好的客群进去。随着业务规模做大和风控样本积累，此时需要在风险容忍度可接受范围内提升通过率，以保持收益的最大化。如果某一天风控通过率忽然降低，这种情况下策略分析人员应该如何应对？</p>
<h3 id="1-寻找通过率下降的时间点或时间段"><a href="#1-寻找通过率下降的时间点或时间段" class="headerlink" title="1 寻找通过率下降的时间点或时间段"></a>1 寻找通过率下降的时间点或时间段</h3><p>在风控策略稳定之后，审批通过率一般稳定在某一小范围内波动，当监控每日通过率指标时发现，T-1、T-2时点的通过率明显下降，我们应该先通过监控报表迅速定位到具体时间点或时间段。</p>
<p>明显发现2019.6.23和6.24授信通过率下降。</p>
<h3 id="2-判断策略节点主次要拒绝影响"><a href="#2-判断策略节点主次要拒绝影响" class="headerlink" title="2 判断策略节点主次要拒绝影响"></a>2 判断策略节点主次要拒绝影响</h3><p>发现通过率下降的时间点或时间段之后，下一步先聚焦到策略节点。本文为FALers举例两个策略节点A（准入）和B（规则）。以6月23日为时间节点划分，对比数据分析，寻找拒绝率的波动差。按照B段A节点拒绝率-A段A节点拒绝率计算出来，以此类推。此时计算波动差仍然可以考虑加入PSI=(B-A)*LN(B/A)测算波动差,A节点的PSI为0.77%，B节点的PSI为0.01%。按照波动差确定通过率的下降主要因为A节点的拒绝率上升引起，从而将通过率下降的影响因素从策略A和B两个节点问题进一步聚焦到A节点上。</p>
<h3 id="3-从节点聚焦到节点规则层深度分析"><a href="#3-从节点聚焦到节点规则层深度分析" class="headerlink" title="3 从节点聚焦到节点规则层深度分析"></a>3 从节点聚焦到节点规则层深度分析</h3><p>完成节点的聚焦分析，定位到引起通过率下降的主要原因节点A，接下来需要进一步分析节点A内包含的所有规则拒绝情况。<br>与节点聚焦分析一致，寻找引起拒绝率上升的主次要拒绝规则。在规则层确定主次要影响因子时，分析方法不仅结合数据同时也参考业务场景。<br>从上图示例4可以发现，按照波动差分析得出年龄准入拒绝和X3_准入拒绝是主要引起通过率下降的规则。</p>
<h3 id="4-具体规则分布分析"><a href="#4-具体规则分布分析" class="headerlink" title="4 具体规则分布分析"></a>4 具体规则分布分析</h3><p>从步骤3确定出年龄准入拒绝是第一位引起通过率下降的规则后，第四步就从规则层聚焦到具体策略规则的分布上。</p>
<p>通过分析具体策略规则分布的波动差定位具体策略规则的某一分布，找出引起通过率下降的主要策略分布。从上图示例发现，年龄准入拒绝这一策略规则中，18-25岁的分布拒绝率在时间A段和时间B段的波动差最大，这个年龄分布的拒绝率上升可能是引起整个审批通过率下降的主要规则分布。造成以上18-25岁年龄分布拒绝增加的原因，很常见的一种是进件客群发生了变化，针对客群发生突然变化的情况，如何将分析结果指导决策执行，是策略分析最后且最重要的一步。</p>
<h3 id="5-分析指导决策"><a href="#5-分析指导决策" class="headerlink" title="5 分析指导决策"></a>5 分析指导决策</h3><p>仍以上述案例为例，通过一系列聚焦分析发现，18-25岁的进件客群变化是引起整体通过率下降的核心因素。实际业务场景中，并不会因为此时通过率突降就进行策略规则的调整，更多的是通过聚焦分析后，结果进一步细分两个参照要素：进件渠道的进件量分布和最大进件渠道的年龄准入拒绝分布。<br>5.1.进件渠道分布分析<br>既然是客群的变化引起了整体审批通过率的下降，从进件的所有渠道数据中进行分布排序，定位到渠道进件量A段和B段都最大的一个进件渠道C。<br>5.2.最大进件渠道的年龄准入拒绝分布<br>通过进件渠道进件量分析，从众多进件渠道中定位到最大进件渠道C。此时分析主要拒绝规则-年龄准入拒绝的渠道C的分布情况，是否满足条件：B段与A段年龄18-25岁的波动变高。<br>从上图示例8中分析发现，渠道C年龄在18-25岁的客群进件量在B段比A段上升明显，即从渠道进件前段业务确定出引起通过率降低的主要进件渠道C。至此，可以进行策略分析决策建议。<br>5.3.决策建议<br>将策略分析结果应用于前段业务指导和决策，提醒前端业务人员在渠道C可以适当缩紧18-25岁客群的进件需求，以此共同维护金融公司整体风控通过率，这才是风控策略分析工作者最终的使命和义务。</p>
<h3 id="6-逾期率上升的策略调整"><a href="#6-逾期率上升的策略调整" class="headerlink" title="6 逾期率上升的策略调整"></a>6 逾期率上升的策略调整</h3><p>当逾期升高时，如何进行策略调优。真实案例背景（数据已脱敏）：通过PQR监控报表发现，某XX贷产品的MOB报表自2019年5月开始，后续放款月资产逾期呈上升趋势，既DPD30+逐月上升，且上升速度逐步增快（MOB期数逐渐缩短）。在2019年11月放款的客户里，MOB=4的DPD30+等于2.49%。如下图1所示。</p>
<p>通过将MOB制作成Vintage报表，可以观测到某XX贷产品的风险自2019年5月到11月的DPD30+平均值位于6%的水平，如下图2所示。</p>
<p>往期DPD30+表现出的风险水平逐月快速上升现象，意味着如果不做相应的策略调整，之后的放款月风险将会更快的暴露。<br>针对此时逾期快速上升的背景下，如何分析策略，进行策略调整呢？<br>策略分析方法<br>第一步：确定存量还是新增客户导致逾期上升<br>信贷业务每个月发生授信和放款的客户可以分成新增客户和存量客户。从上图示例2中Vintage报表展现的数据，反映出资产逾期呈上升趋势。那我们首先需要将2019年5月到2019年11月（可观测到DPD30+）的Vintage分成新增客户的Vintage1和存量客户的Vintage2，如下图3。</p>
<p>从上图3的Vintage1（新客户）和Vintage2（存量客户）标注的红色椭圆框可以观测到，新客户的DPD30+平均处于6%，存量客户的DPD30+平均处于5%。与图示1对比可以分析出，导致资产逾期上升的主要原因是新增客户资产变差的影响。至此阶段的分析结论：我们可以确定出需要调整的策略规则是贷前规则。<br>解释如下：往期放款月中，新客户是由贷前规则通过后，给予授信并放款的，存量客户的复借是由贷中规则决定。通过Vintage1和2的分析比对，引起资产逾期上升的主要原因是新客户的逾期上升。<br>第二步：多维度分析，找出最主要影响规则<br>通过第一步的分析确定出核心要调整的是贷前策略后，我们接下来要通过分析不同的规则变量，找出对目标变量（DPD30+）影响最大的维度变量。<br>这里提供分析主要影响变量的两个思路，具体实践过程就不在这里多讲，文末推荐阅读有链接。<br>思路一：自上而下地按照A类策略调优方法，从贷前策略节点到节点里的规则集，再细分到具体规则，逐步分析出影响较大的规则变量（文末推荐阅读给出具体分析的往期文链接）<br>思路二：自下而上地将所有规则变量与目标变量拟合分析，通过IV的降序排序，找出影响较大的规则变量。<br>分析得出，城市等级是影响逾期目标上升的主要变量。通过分析2019年5月至11月的城市等级Vintage曲线，可以发现“其他城市”较“一线城市”、“二线城市”、“三线城市“对逾期的影响较大，如下图。</p>
<p>第三步：制定策略调整方案<br>通过上述数据分析，发现贷前风控规则里的“城市等级”规则”其他城市“是导致逾期升高的主要原因。此时容易出现的一个错误决策是拒绝“其他城市”的进件。<br>原因很简单：这种决策会导致大量的申请被拒绝，对通过率的影响比较大。<br>最优的策略调整方案思路是：从“坏客户”中挑选出“最坏”的一批客户，且这批客户的占比较少，然后加以拒绝。<br>按照上述思路，我们可以制定出如下的策略优化方案：<br>1、进一步分析“其他城市”里，哪一些的城市逾期较高；2、挑选部分逾期较高的城市做贷前准入规则。以上，就是逾期升高情况下，策略调优的分析方法。</p>
<h3 id="7-信用多头策"><a href="#7-信用多头策" class="headerlink" title="7 信用多头策"></a>7 信用多头策</h3><p>金融风险管理中，对于一个借款人还款能力的评估十分重视。如果一个人的资产负债比过大，一旦发生资不抵债的现象，金融机构继续对其发放贷款发生违约的风险是极大的。在体现借款人甚至借款企业还款能力的众多指标中，多头借贷是一项核心指标。<br>1.什么是多头借贷<br>多头借贷是指单个借款人向2家或2家以上的金融机构提出借贷需求的行为。多头借贷数据一般至少会粗分成银行类多头借贷、非银类多头借贷。按时间跨度可以分为近7天、近15天、近1个月、近3个月、近6个月、近12个月。</p>
<p>多头借贷除了会统计申请次数，还会统计申请机构数、申请最大间隔天数、申请最小间隔天数、申请记录月份、平均每月申请次数(有申请月份平均)、最大月申请次数、最小月申请次数等。由于单个用户的偿还能力是有限的，向多方借贷必然蕴含着较高的风险。一般来说，当借贷人出现了多头借贷的情况，说明该借贷人资金出现了较大困难，有理由怀疑其还款能力。<br>2.多头借贷数据的分析方法<br>由于多头借贷可以比较有效的反应借款人的还款能力，所以在对借款人信用风险、欺诈风险评估上，基本都有使用多头借贷数据。多头借贷作为一个衡量借款人的维度特征，可以结合一些逾期指标进行分析。对近7天非银机构申请机构平台数进行分析，对申请不同平台数的客户，分别统计客群的分布占比、FPD30%、FPD30-DPD90+%、通过单量、FPD30单量、DPD90+单量以及DPD90+%。通过统计后的数据，分析近7天申请N平台数的客户，其不同逾期指标的变化趋势，如FPD30%的增幅，进一步用于寻找策略切点或者豁免客群的回顾分析。<br>3.多头借贷数据为何少用于模型<br>多头借贷少出现在模型变量中，主要有两个方面原因。<br>第一，多头借贷数据往往被策略同事应用于规则中。<br>数据建模的目的是从金融弱变量中通过特征工程方法，提炼出有效区分变量，构建评分模型。所以对于多头借贷数据，既然已经运用在策略规则中，实在没必要加入到模型变量。如果读者朋友们看到提交的评分模型报告中有多头借贷变量，那么建模的同事要么没有事先了解已上线运行的策略规则集，要么就是为了模型表现指标（如KS、AR、AUC）好看强行使用。<br>第二，多头借贷数据往往覆盖度不全。<br>多头借贷虽然是一个与风险强关联的维度，但其查得率一直被人所诟病。举一个例子，借款人一个月内在多家机构贷款，作为一个特征，很有可能出现某个人虽然频繁贷款，但并没有被多头供应商捕捉到。一旦这个特征作为模型变量，那么这个变量的噪声就很大了。反而如果做成反欺诈策略，就不需要担心噪声问题，直接选取拒绝线进行截断，最大的影响，也就是没有拒绝掉足够多的用户，而这个影响我们还可以用噪声较小的模型进行弥补。<br>4.多头借贷数据在策略规则上的应用<br>多头借贷在策略上一般作为一条策略规则，一个拒绝维度参与到整个风控流程中。不同机构，不同信贷产品，不同场景，对于多头借贷的拒绝线划分都是不一样的。如何找到当下最适合的多头借贷拒绝线，对于风控策略分析人员，是风控工作的核心任务。仍以上图示例1为例，假设当前对于7天多平台数规则的拒绝线划分在6，即如果7天多平台数&gt;=7则拒绝。如果我们现在希望通过7天多平台数规则豁免一部分客群提升整体通过率，此时的拒绝线cutoff应该划分在哪里呢？如果不是应对紧急调整通过率的情况，我们可以事先豁免7天多平台数7-10的客户，作为测试样本，用以产生7-10客群通过单量的分布，之后将拒绝线调回6。既可以生成如下统计分析表：<br>上图示例2中的桔色部分都是通过分析预测出来，比如通过上图示例1中不同多平台数FPD30%的平均增幅0.7%，预测出7-10的FPD30%。预估计算公式8FPD30%=7FPD30%+0.7%。进一步计算出FPD30量、DPD90量等其他指标。因为我们对于资产风险管控最关心的逾期指标还是不良率，所以我们通过FPD30-DPD90+%的迁徙率预测出不同7天多平台数的DPD90+%。对于7-10的FPD30-DPD90+%预估，可以采用MAX(0-6的FPD30-DPD90+%)的预估方法。在这之后，我们对于不同7天多平台数测算出拒绝线Cutoff的FPD%和DPD%，规则拒绝线设定在&gt;=7时DPD%=3.0%，设定在&gt;=8时DPD%=3.0%，设定在&gt;=9时DPD%=3.3%。规则拒绝线设定在&gt;=8的DPD%并没有增加。此时可以尝试建议将7天多平台数的拒绝线调整到7。<br>当然，这种策略分析方法仍有一些纰漏，比如此方法需要有测试样本进行观测，无法满足快速调整通过率的需求；7天多平台数的FPD30%的增幅实际情况并非线性增长，有经验的策略分析师知道，FPD30%一定会在某一个节点指数级增长。但正是因为策略分析师通过不断地按照上述方法进行样本测试对照，根据实际情况回顾分析结果，才能不断的积累策略调整经验，才会对规则分布具有一定敏感性。    </p>
<h3 id="8-评分的策略应用"><a href="#8-评分的策略应用" class="headerlink" title="8 评分的策略应用"></a>8 评分的策略应用</h3><p>评分卡模型的运用，主要是为了解决两大问题：<br>1、线上借贷业务量逐渐增加的情景下，策略规则已经无法满足更细的切分需求；<br>2、对于策略无法有效识别的大量灰色客群，需要使用评分卡进行风险判断；<br>现如今业界使用评分卡模型，更多的是为了解决第二个问题。<br>从金融机构自身业务发展历程来看，评分卡模型介入风险管理流程常常取决于两个重要的时机：<br>1、金融机构业务快速发展阶段<br>在金融机构业务发展的早期阶段，因为业务量小、样本少、风险控制严格等一些主客观原因，使用风控策略规则足以开展业务，所以在业务发展早期评分模型基本没有任何用武之地。<br>但随着信贷产品的测试期结束，金融机构要加快业务发展，此时不论是大量的客群样本、逾期表现的积累，还是风险控制的政策放松，都因为风险策略无法精准细分的局限性，而需要评分模型的介入，评分卡的应用场景更适用于人工分流。<br>此阶段的评分模型，常常表现不稳定，比如KS波动较大，Lift下降较快，PSI时常过0.1。此阶段评分模型的优化更多在于分析波动原因，快速重新开发迭代。<br>2、金融机构业务发展稳定阶段<br>一旦金融机构度过了新产品的早期和发展期，此时产品市场表现已经趋向稳定，反应在客群分析上，表现出稳定层级的客户画像，此阶段是评分模型介入2.0阶段。<br>在这个阶段评分模型会在风控流程节点上进行一些调整，比如申请卡模型会进一步的前置，担当部分客群豁免的功能。同时，此时评分模型介入2.0阶段也会降低一些外部征信数据调用成本，控制因三方数据有误而引起的误杀。<br>此阶段的评分模型，表现较为稳定，KS、Lift、PSI等指标波动较小，对于评分卡的迭代开发需求降低，评分卡的应用更加与业务需求、金融政策以及企业发展战略相关，在保证评分模型稳定性及相对精准度的前提下，使用模型调整系数进行全局模型的调整是此阶段的主要优化办法。</p>
<h2 id="9-评分模型的cutoff"><a href="#9-评分模型的cutoff" class="headerlink" title="9 评分模型的cutoff"></a>9 评分模型的cutoff</h2><p>评分卡分数转换出来，在不同业务发展阶段如何合理的制定评分的cutoff，是评分应用重要的一步。<br>一般将评分等分后，会有两种方式对评分进行cutoff：一种是参照KS和Cum % bad rate,另一种根据等分后的累计净收益。<br>第一种参照Max KS和累积bad rate理论上是可以尽可能的将坏客户剔除，对好客群进行授信，但无法根据业务发展需要保证收益最大化。参照不同业务发展阶段的需求，根据评分对收益损失预估，最终确定评分cutoff，我认为这才是精细化的评分应用策略。<br>第二种制定评分的cutoff，需要联动分析以下的一些指标<br>评分cutoff：分数排序、剔除组后的bad rate%、收益、损失、调整后损失、资金成本、净收入。<br>通过逆向累计净收入指标的分析，结合当下风控政策，综合评定评分的cutoff，将之应用在风控策略上，这样才是更接近业务的评分cutoff。</p>
<h1 id="05-模型与策略的楚河汉界"><a href="#05-模型与策略的楚河汉界" class="headerlink" title="-05- 模型与策略的楚河汉界"></a>-05- 模型与策略的楚河汉界</h1><p>众所周知，当下评分模型在金融信贷风控领域的应用非常广泛，模型的开发、监控也趋于标准化。评分模型可以为每一位观测对象打出一个评分分数，理论上实现风险与定价的绝对对等，实现个体差异化的风险管理，在这点上，风险策略规则是远不可及的。<br>此时就有了风险策略与模型之间的争议：模型是否可以替代所有的策略规则？（排除政策准入规则）</p>
<h2 id="1-风险决策的架构"><a href="#1-风险决策的架构" class="headerlink" title="1) 风险决策的架构"></a>1) 风险决策的架构</h2><p>想要回答上述的争议，首先需要了解目前策略规则与模型在风控决策体系里的应用架构。目前我所见到有两种主流的风控决策应用架构：策略规则+评分模型 &amp; 策略规则+模型规则。<br>前者策略规则和评分模型是分开的，一般风控流程是先进行策略规则的风险判断，再进入评分模型的风险识别；后者是将评分模型的预测概率（或分数）转变为一个策略规则，与其他策略规则融合在一起进行风险决策。</p>
<h2 id="2-策略规则的粗放式管理"><a href="#2-策略规则的粗放式管理" class="headerlink" title="2) 策略规则的粗放式管理"></a>2) 策略规则的粗放式管理</h2><p>策略规则作为一种风险识别的方法，其自身具有直观、易用等特性。对于新产品上线前的风险决策，因为没有数据样本的原因，策略规则在风险决策初期起到不可替代作用。但也因为策略规则的设定原理，其自身很难做到风险决策的精细化管理。<br>以上图风险决策B为例，可以看出策略规则都是XXXX&gt;xxx，这种单维度的风险判断是存在一定的取舍。比如某金融机构的一条多头借贷策略规则设定为：多头借贷平台数&gt;5则执行拒绝，那多头借贷=6的申请客户，就一定会违约吗？<br>说到这里可能会有读者朋友质疑：我可以设定一些策略规则组合起来判断。没错，这也是风险决策体系下策略规则应用的一种方式，但不论多少维度的组合判断，都必然会对单一维度策略规则进行True or False判断。比如上例中的策略规则变为：多头借贷&gt;5 或 多头借贷&gt;6且性别为男性，则执行拒绝。此时对于多头借贷=6的女性不会拒绝，但对于多头借贷=7且有一定储蓄的男性，就一定会违约吗？可以看出，如果希望通过策略规则的组合实现精细化的风险管理，就会不断地增加策略规则，最终导致策略规则的复杂和冗余，对于策略优化、回顾并没有正向的影响，这与策略规则的易用、直观等特性产生了矛盾。</p>
<h2 id="3-评分模型的常见三种盲区"><a href="#3-评分模型的常见三种盲区" class="headerlink" title="3) 评分模型的常见三种盲区"></a>3) 评分模型的常见三种盲区</h2><p>由于策略规则的先天性缺陷，评分模型的出现可以恰当的弥补策略规则的不足，但并不意味着评分模型可以完全替代所有的策略规则。其原因有风控流程的考虑、业务发展的考虑等。<br>建模数据集与实际贷款人之间存在偏差<br>在中国因为征信体系的不完善，金融机构的模型一般以实际贷款人作为模型数据集，而申请人母集到贷款人子集往往发生较大变化（就算是大家熟知的拒绝推断也只能尽量弥补但不能完全拒绝这方面的误差），模型的判断就会出现一些偏差，此时需要根据策略维度的一些拒绝线，对模型进行一些矫正和保护。<br>模型数据集来自历史，与未来实际情况存在偏差<br>模型是基于历史数据找到数据之间的逻辑规律后，对未来事件进行预测。对于具有周期性的金融行业，如果用处于上升期的数据模型预测金融衰退期的事件，必然会与实际情况发生偏差。<br>举个例子，比如在经济上升或者繁荣期，消费者不仅有工作的单一收入，消费者可以从一些兼职等渠道获取额外的收入来源，此时即使有较高负债收入比的客群仍然可以维持较好的信用表现；但当经济开始进入下滑时期，未来消费者很难继续从其他渠道获取资金，即使历史数据告诉模型、模型告诉决策人，此时的借贷申请人有还款能力和意愿，但商业风险决策者应考虑收紧对于较高负债收入比人群的贷款。<br>模型对于目标变量的界定与实际商业目标存在偏差<br>模型为了权衡观察期的代表性和表现期的时效性，在建模时为了囊括最近的贷款数据，在界定“坏账”定义时，仅考虑前12个月的还款表现（有时仅考虑前6个月），此时对于一些中额长期的信贷产品（比如24个月、36个月），模型目标变量的界定与实际商业目标就发生了偏差。<br>综上，从反面辩证性的角度分析模型与策略，二者缺一不可，谁也不可能完全替代对方。通过科学地搭配，共同构架起严谨的风险决策体系。</p>
]]></content>
      <tags>
        <tag>风控</tag>
        <tag>信贷</tag>
        <tag>策略</tag>
      </tags>
  </entry>
  <entry>
    <title>常见机器学习优缺点</title>
    <url>/2020/05/01/%E5%B8%B8%E8%A7%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%BC%98%E7%BC%BA%E7%82%B9/</url>
    <content><![CDATA[<h1 id="1、线性回归："><a href="#1、线性回归：" class="headerlink" title="1、线性回归："></a>1、线性回归：</h1><p>线性回归的基本假设：1、模型对参数是线性的；2、严格外生性：既解释变量x与随机误差项\segma不相关；3、无多重共线性，既解释变量间没有完全线性关系，或者x.T*x是非奇异的；条件同方差：误差项的均值为0，方差为\segma^2；任意两点的误差项不自相关 。   解释变量的联合显著性：F检验  异方差检验：white检验</p>
<a id="more"></a>
<h1 id="2、-logistic回归"><a href="#2、-logistic回归" class="headerlink" title="2、 logistic回归"></a>2、 logistic回归</h1><p>基础思想：logistic回归属于对数线性模型，是一种分类算法。Logistic在输出值上施加sigmoid函数将值收敛到0~1范围。logitisc中y是一个定型变量，比如y=0或1，logistic方法主要应用于研究某些事件发生的概率，广泛运用于评分卡模型。优点 ：1）速度快，适合二分类问题；2）简单易于理解，直接看到各个特征的权重；3）能容易地更新模型吸收新的数据。缺点：对数据和场景的适应能力有局限，不如决策树算法适应性那么强。容易欠拟合。</p>
<h1 id="3、朴素贝叶斯"><a href="#3、朴素贝叶斯" class="headerlink" title="3、朴素贝叶斯"></a>3、朴素贝叶斯</h1><p>1)基础思想：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此分类项属于哪个类别。最大化后验概率   2)优点：方法简单，分类准确率高，速度快，所需估计的参数少，对于缺失数据不敏感。3)缺点：假设样本特征彼此独立，这往往并不成立。(喜欢吃番茄、鸡蛋，却不喜欢吃番茄炒蛋)。需要知道先验概率。</p>
<h1 id="4、SVM"><a href="#4、SVM" class="headerlink" title="4、SVM"></a>4、SVM</h1><p>支持向量机是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器。<br>1）基础思想：支持向量机把分类问题转化为寻找分类平面的问题，并通过最大化分类边界点距离分类平面的距离来实现分类。2）优点 ：可以解决小样本下机器学习的问题；提高泛化性能；可以解决文本分类、文字识别、图像分类等方面仍受欢迎；避免神经网络结构选择和局部极小的问题。3）缺点：缺失数据敏感；内存消耗大，难以解释。<br>多项式核  拉普拉斯核  Sigmoid核等</p>
<h1 id="5、决策树"><a href="#5、决策树" class="headerlink" title="5、决策树"></a>5、决策树</h1><p>1)基础思想：决策树是一种简单但广泛使用的分类器，它通过训练数据构建决策树，对未知的数据进行分类。决策树的每个内部节点表示在一个属性上的测试，每个分枝代表该测试的一个输出，而每个叶结点存放着一个类标号。在决策树算法中，ID3基于信息增益作为属性选择的度量，C4.5基于信息增益比作为属性选择的度量，CART基于基尼指数作为属性选择的度量。<br>2)优点 ：不需要任何领域知识或参数假设；适合高维数据；简单易于理解；短时间内处理大量数据，得到可行且效果较好的结果；  3)缺点：对于各类别样本数量不一致数据，信息增益偏向于那些具有更多数值的特征。易于过拟合。忽略属性之间的相关性。</p>
<h1 id="6、随机森林"><a href="#6、随机森林" class="headerlink" title="6、随机森林"></a>6、随机森林</h1><p>随机森林实际上是一种特殊的bagging方法，它将决策树用作bagging中的模型。首先，生成m个训练集，然后，对于每个训练集，构造一颗决策树，在节点找特征进行分裂的时候，并不是对所有特征找到能使得指标（如信息增益）最大的，而是在特征中随机抽取一部分特征，在抽到的特征中间找到最优解，应用于节点，进行分裂。随机森林的方法由于有了bagging，也就是集成的思想在，实际上相当于对于样本和特征都进行了采样（如果把训练数据看成矩阵，就像实际中常见的那样，那么就是一个行和列都进行采样的过程），所以可以避免过拟合。2）优点：它能够处理很高维度的数据，并且不用做特征选择(因为特征子集是随机选择的)；无偏估计，模型泛化能力强；训练速度快，容易做成并行化方法；对于不平衡的数据集来说，它可以平衡误差。 3）缺点：随机森林已经被证明在某些噪音较大的分类或回归问题上会过拟 ；对于有不同取值的属性的数据，取值划分较多的属性会对随机森林产生更大的影响，所以随机森林在这种数据上产出的属性权值是不可信的。</p>
<h1 id="7、GBDT"><a href="#7、GBDT" class="headerlink" title="7、GBDT"></a>7、GBDT</h1><p>1）GBDT算法是模型为加法模型，学习算法为前向分步算法，基函数为CART树，损失函数为平方损失函数的回归问题。每次迭代中拟合残差来学习一个弱学习器。而残差的方向即为我们全局最优的方向。损失函数负梯度的方向代替残差方向，我们称损失函数负梯度为伪残差。而伪残差的方向即为我们局部最优的方向。所以在GBDT中，当损失函数不为平方损失时，用每次迭代的局部最优方向代替全局最优方向 2）优点：可以灵活处理各种类型的数据，包括连续值和离散值；在相对少的调参时间情况下，预测的准备率也可以比较高。这个是相对SVM来说的；使用一些健壮的损失函数，对异常值的鲁棒性非常强。比如 Huber损失函数和Quantile损失函数；很好的利用了弱分类器进行级联；充分考虑的每个分类器的权重。3）缺点：由于弱学习器之间存在依赖关系，难以并行训练数据。不过可以通过自采样的SGBT来达到部分并行。</p>
<h1 id="8、GBDT和随机森林的区别"><a href="#8、GBDT和随机森林的区别" class="headerlink" title="8、GBDT和随机森林的区别"></a>8、GBDT和随机森林的区别</h1><p>1）相同点：都是由多棵树组成；最终的结果都由多棵树共同决定。2）不同点：a 组成随机森林的树可以分类树也可以是回归树，而GBDT只由回归树组成；b 组成随机森林的树可以并行生成；GBDT 只能串行生成；c 随机森林的结果是多数表决表决的，而GBDT则是多棵树加权累加之和；d 随机森林对异常值不敏感，而GBDT对异常值比较敏感；e 随机森林是减少模型的方差，而GBDT是减少模型的偏差；f 随机森林不需要进行特征归一化。而GBDT则需要进行特征归一化；g 随机森林对训练集一视同仁权值一样，GBDT是基于权值的弱分类器的集成</p>
<h1 id="9、GBDT与Xgboost的区别"><a href="#9、GBDT与Xgboost的区别" class="headerlink" title="9、GBDT与Xgboost的区别"></a>9、GBDT与Xgboost的区别</h1><p>1）传统GBDT以CART作为基分类器，xgboost还支持线性分类器，这个时候xgboost相当于带L1和L2正则化项的逻辑斯蒂回归（分类问题）或者线性回归（回归问题）。2）传统GBDT在优化时只用到一阶导数信息，xgboost则对代价函数进行了二阶泰勒展开，同时用到了一阶和二阶导数。3）xgboost在代价函数里加入了正则项，用于控制模型的复杂度。4）列抽样（column subsampling）。xgboost借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算。5）对缺失值的处理。对于特征的值有缺失的样本，xgboost可以自动学习出它的分裂方向。6）xgboost工具支持并行。</p>
<h1 id="10、bagging和boosting的区别"><a href="#10、bagging和boosting的区别" class="headerlink" title="10、bagging和boosting的区别"></a>10、bagging和boosting的区别</h1><p>1）样本选择上：Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。<br>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。   2）样例权重：Bagging：使用均匀取样，每个样例的权重相等；Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。  3）预测函数：Bagging：所有预测函数的权重相等。Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。 4）并行计算：Bagging：各个预测函数可以并行生成；Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。 5）bagging是减少variance，子模型有一定的相关性；而boosting是减少bias，forward-stagewise这种贪心法去最小化损失函数</p>
<h1 id="11、聚类"><a href="#11、聚类" class="headerlink" title="11、聚类"></a>11、聚类</h1><h2 id="k-means原理："><a href="#k-means原理：" class="headerlink" title="k-means原理："></a>k-means原理：</h2><p>K均值算法比较简单。首先，选择K个初始质心，其中K是用户指定的参数，既所期望的族的个数。每个点指派到最近的质心，而指派到一个质心的点集为一个族。然后，根据指派到族的点，更新每个族的质心。重复指派和更新步骤，直到族不发生变化，或等价地，直到质心不发生变化。  最小化每个点到最近质心的距离的平方，也可以用均值作为质心）  改进：二分K均值   2）优点: 原理简单，实现方便，收敛速度快; 聚类效果较优；模型的可解释性较强；调参只需要簇数k；3）缺点：k的选取不好把握；对于不是凸的数据集比较难以收敛；如果数据的类型不平衡，比如数据量严重失衡或者类别的方差不同，则聚类效果不佳；采用的是迭代的方法，只能得到局部最优解；对于噪音和异常点比较敏感。</p>
<h2 id="层次聚类："><a href="#层次聚类：" class="headerlink" title="层次聚类："></a>层次聚类：</h2><p>从点作为个体族开始，每一步合并两个最接近的族，直到只剩下一个族。定义族之间的邻近性： MIN：族的邻近点为不同族的两个最近的点之间邻近度；MAX：不同族中两个最远的点之间的邻近度作为族的邻近度；组平均：取自不同族的所有点对邻近度的平均值</p>
<h2 id="密度聚类："><a href="#密度聚类：" class="headerlink" title="密度聚类："></a>密度聚类：</h2><p>优点：相对抗噪声，并且能够处理任意形状和大小的族。能克服基于距离的算法只能发现‘类圆形’的聚类的缺点。缺点：族的密度变化太大，或者高维数组，不够精确。</p>
<h1 id="12、PCA"><a href="#12、PCA" class="headerlink" title="12、PCA"></a>12、PCA</h1><p>即主成分分析方法，是一种使用最广泛的数据降维算法。PCA的主要思想是将n维特征映射到k维上，这k维是全新的正交特征也被称为主成分，是在原有n维特征的基础上重新构造出来的k维特征。PCA的工作就是从原始的空间中顺序地找一组相互正交的坐标轴，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是原始数据中方差最大的方向，第二个新坐标轴选取是与第一个坐标轴正交的平面中使得方差最大的，第三个轴是与第1,2个轴正交的平面中方差最大的。依次类推，可以得到n个这样的坐标轴。</p>
<h1 id="13、过拟合和欠拟合"><a href="#13、过拟合和欠拟合" class="headerlink" title="13、过拟合和欠拟合"></a>13、过拟合和欠拟合</h1><p>过拟合：训练出来的模型过拟合了训练集, 对训练集外的数据却预测不准, 这称泛化性能不好。解决方法：1）正则化；2）增加数据量；3）减少模型特征，降低模型复杂度；4）减少训练次数。欠拟合：1）增加数据量；2）增加衍生特征，增加模型复杂度；</p>
<h1 id="14、SVM-和-LR-的区别"><a href="#14、SVM-和-LR-的区别" class="headerlink" title="14、SVM 和 LR 的区别"></a>14、SVM 和 LR 的区别</h1><p>相同点：1）都是线性分类器。本质上都是求一个最佳分类超平面；2）都是监督学习算法。  不同点：本质上是损失函数不同，LR的损失函数是交叉熵：SVM荷叶损失函数；2）两个模型对数据和参数的敏感程度不同 3） SVM 基于距离分类，LR 基于概率分类。 </p>
<h1 id="15、模型评估"><a href="#15、模型评估" class="headerlink" title="15、模型评估"></a>15、模型评估</h1><p>KS：KS用于模型风险区分能力进行评估， 指标衡量的是好坏样本累计分部之间的差值。好坏样本累计差异越大，KS指标越大，那么模型的风险区分能力越强；<br>Precision：是指在所有系统判定的“真”的样本中，确实是真的的占比； = 1-假真率；<br>Recall：是指在所有确实为真的样本中，被判为的“真”的占比    = 真正率；<br>ROC曲线：横坐标为False Positive Rate(FPR假正率)，纵坐标为True Positive Rate(TPR真正率)；<br>AUC：ROC曲线下的面积，通常大于0.5，小于1；</p>
<h1 id="16、主成分分析（PCA）与因子分析的区别"><a href="#16、主成分分析（PCA）与因子分析的区别" class="headerlink" title="16、主成分分析（PCA）与因子分析的区别"></a>16、主成分分析（PCA）与因子分析的区别</h1><ul>
<li>主成分分析是通过变量变换把注意力集中在具有较大方差的那些主成分上，而舍弃那些方差小的主成分；因子分析是因子模型把注意力集中在少数不可观测的潜在变量（即公共因子）上，而舍弃特殊因子。</li>
<li>主成分分析是将主成分表示为原观测变量的线性组合， 因子分析则是对原观测变量分解成公共因子和特殊因子两部分</li>
<li>主成分的各系数w，是唯一确定的、正交的。不可以对系数矩阵进行任何的旋转，且系数大小并不代表原变量与主成分的相关程度；而因子模型的系数矩阵是不唯一的、可以进行旋转的，且该矩阵表明了原变量和公共因子的相关程度。</li>
<li>主成分分析，可以通过可观测的原变量X直接求得主成分Y，并具有可逆性；因子分析中的载荷矩阵是不可逆的，只能通过可观测的原变量去估计不可观测的公共因 子，即公共因子得分的估计值等于因子得分系数矩阵与原观测变量标准化后的矩阵相乘的结果。还有，主成分分析不可以像因子分析那样进行因子旋转处理。</li>
<li>综合排名。主成分分析一般依据第一主成分的得分排名，若第一主成分不能完全代替原始变量，则需要继续选择第二个主成分、第三个等等，此时综合得分=∑ （各主成分得分×各主成分所对应的方差贡献率）,主成分得分是将原始变量的标准化值，代入主成分表达式中计算得到；而因子分析的综合得分=∑（各因子得分 ×各因子所对应的方差贡献率）÷∑各因子的方差贡献率，因子得分是将原始变量的标准化值，代入因子得分函数中计算得到。</li>
</ul>
]]></content>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive操作</title>
    <url>/2020/04/18/Hive%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h1 id="1、小表join大表原则；"><a href="#1、小表join大表原则；" class="headerlink" title="1、小表join大表原则；"></a>1、小表join大表原则；</h1><p>Hive中的常用基本数据类型：<br>|数据类型 | 长度 | 备注|<br>|—-|—-|—-|<br>| Tinyint | 1字节的有符号整数 | -128~127 |<br>| SmallInt | 1个字节的有符号整数 | -32768~32767 |<br>| Int | 4个字节的有符号整数 | -2147483648 ~ 2147483647 |<br>| BigInt | 8个字节的有符号整数 | |<br>| Boolean | 布尔类型，true或者false true、false | |<br>| Float | 单精度浮点数 | |<br>| Double | 双精度浮点数 | |<br>| String | 字符串 | |<br>| TimeStamp | 整数 | 支持Unix timestamp，可以达到纳秒精度 |<br>| Binary | 字节数组  | |<br>| Date | 日期 | 0000-01-01 ~ 9999-12-31，常用String代替 |<br><a id="more"></a></p>
<h1 id="2、具体语法"><a href="#2、具体语法" class="headerlink" title="2、具体语法"></a>2、具体语法</h1><p>创建数据库例子：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; create database if not exists user_db;</span><br></pre></td></tr></table></figure><br>查看数据库定义：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; describe database user_db;</span><br></pre></td></tr></table></figure><br>查看数据库列表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure><br>删除数据库：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; drop database if exists testdb cascade;</span><br></pre></td></tr></table></figure><br>切换当前数据库：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; use user_db;</span><br></pre></td></tr></table></figure></p>
<p>创建普通表：<br>1)第一种<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; create table if not exists userinfo  </span><br><span class="line">    (</span><br><span class="line">    userid int,</span><br><span class="line">    username string,</span><br><span class="line">    cityid int,</span><br><span class="line">    createtime date    </span><br><span class="line">    )</span><br><span class="line">    row format delimited fields terminated by &#39;\t&#39;</span><br><span class="line">    stored as textfile;</span><br></pre></td></tr></table></figure><br>row format delimited fields terminated by ‘\t’ 是指定列之间的分隔符；stored as textfile是指定文件存储格式为textfile。</p>
<p>2）第二种<br>create table as select 方式：根据查询的结果自动创建表，并将查询结果数据插入新建的表中。</p>
<p>3）第三种<br>create table like tablename1 方式：是克隆表，只复制tablename1表的结构。复制表和克隆表会在下面的Hive数据管理部分详细讲解。</p>
<p>创建外部表：<br>外部表是没有被hive完全控制的表，当表删除后，数据不会被删除。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; create external table iislog_ext (</span><br><span class="line">    ip string,</span><br><span class="line">    logtime string    </span><br><span class="line">    );</span><br></pre></td></tr></table></figure></p>
<p>创建分区表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table user_action_log</span><br><span class="line">(</span><br><span class="line">companyId INT comment   &#39;公司ID&#39;,</span><br><span class="line">userid INT comment   &#39;销售ID&#39;,</span><br><span class="line">originalstring STRING comment   &#39;url&#39;, </span><br><span class="line">)</span><br><span class="line">partitioned by (dt string)</span><br><span class="line">row format delimited fields terminated by &#39;,&#39;</span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure></p>
<p>创建桶表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table user_leads</span><br><span class="line">(</span><br><span class="line">leads_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_id string,</span><br><span class="line">user_phone string,</span><br><span class="line">user_name string,</span><br><span class="line">create_time string</span><br><span class="line">)</span><br><span class="line">clustered by (user_id) sorted by(leads_id) into 10 buckets </span><br><span class="line">row format delimited fields terminated by &#39;\t&#39; </span><br><span class="line">stored as textfile;</span><br></pre></td></tr></table></figure></p>
<p>查看简单定义：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">describe userinfo;</span><br></pre></td></tr></table></figure></p>
<p>查看表详细信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">describe formatted userinfo;</span><br></pre></td></tr></table></figure></p>
<p>修改表名：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table userinfo rename to user_info;</span><br></pre></td></tr></table></figure></p>
<p>添加字段：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table user_info add columns (provinceid int );</span><br></pre></td></tr></table></figure></p>
<p>修改字段：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table user_info replace columns (userid int,username string,cityid int,joindate date,provinceid int);</span><br></pre></td></tr></table></figure></p>
<p>将本地文本文件内容批量加载到Hive表中：<br>——要求文本文件中的格式和Hive表的定义一致<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;home&#x2F;hadoop&#x2F;userinfodata.txt&#39; overwrite into table user_info;</span><br></pre></td></tr></table></figure></p>
<p>加载到分区表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">load data local inpath &#39;&#x2F;home&#x2F;hadoop&#x2F;actionlog.txt&#39; overwrite into table user_action_log PARTITION (dt&#x3D;&#39;2017-05-26’);</span><br></pre></td></tr></table></figure></p>
<p>导入分桶表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set hive.enforce.bucketing &#x3D; true;</span><br><span class="line">insert overwrite table user_leads select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure></p>
<p>导出数据：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert overwrite local directory &#39;&#x2F;home&#x2F;hadoop&#x2F;user_info.bak2016-08-22&#39;</span><br><span class="line">row format delimited</span><br><span class="line">fields terminated by &#39;\t&#39; --指定分割符</span><br><span class="line">select * from user_info;</span><br></pre></td></tr></table></figure></p>
<p>插入数据的表是分区表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert overwrite table user_leads PARTITION (dt&#x3D;&#39;2017-05-26&#39;) </span><br><span class="line">select * from  user_leads_tmp;</span><br></pre></td></tr></table></figure></p>
<p>复制表：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table user_leads_bak</span><br><span class="line">row format delimited fields terminated by &#39;\t&#39;</span><br><span class="line">stored as textfile</span><br><span class="line">as</span><br><span class="line">select leads_id,user_id,&#39;2016-08-22&#39; as bakdate</span><br><span class="line">from user_leads</span><br><span class="line">where create_time&lt;&#39;2016-08-22’;</span><br></pre></td></tr></table></figure></p>
<p>克隆表：<br>——克隆表时会克隆源表的所有元数据信息，但是不会复制源表的数据<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table user_leads_like like  user_leads;</span><br></pre></td></tr></table></figure></p>
<h1 id="3、Where筛选："><a href="#3、Where筛选：" class="headerlink" title="3、Where筛选："></a>3、Where筛选：</h1><p>操作符 说明<br>A=B   A等于B就返回true，适用于各种基本类型<br>A&lt;=&gt;B   都为Null则返回True，其他和=一样<br>A&lt;&gt;B   不等于<br>A!=B   不等于<br>A<B 小于 a<="B" 小于等于 a>B   大于<br>A&gt;=B   大于等于<br>A Between B And C   筛选A的值处于B和C之间<br>A Not Between B And C   筛选A的值不处于B和C之间<br>A Is NULL   筛选A是NULL的<br>A Is Not NULL   筛选A值不是NULL的<br>A Link B   %一个或者多个字符_一个字符<br>A Not Like B   %一个或者多个字符_一个字符<br>A RLike B   正则匹配 </B></p>
<h1 id="4、排序："><a href="#4、排序：" class="headerlink" title="4、排序："></a>4、排序：</h1><p>Sort By：<br>——Hive中尽量不要用Order By，除非非常确定结果集很小<br>select * from user_leads sort by user_id</p>
<p>日期函数：</p>
<p>1、UNIX时间戳转日期函数：from_unixtime<br>转化UNIX时间戳（从1970-01-01 00:00:00 UTC到指定时间的秒数）到当前时区的时间格式<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select from_unixtime(1323308943,&#39;yyyyMMdd&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>2、日期时间转日期函数：to_date<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select to_date(&#39;2011-12-08 10:03:01&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure><br>3、日期转年\月\日函数：year——month——day<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select year(&#39;2011-12-08 10:03:01&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure><br>4、日期比较函数：datediff<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select datediff(&#39;2012-12-08&#39;,&#39;2012-05-09&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>5、日期增加、减少函数：date_add/date_sub<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select date_add(&#39;2012-12-08&#39;,10) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<h1 id="5、字符串函数："><a href="#5、字符串函数：" class="headerlink" title="5、字符串函数："></a>5、字符串函数：</h1><p>1、字符串反转函数：reverse<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select reverse(abcedfg’) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>2、字符串连接函数：concat<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select concat(‘abc’,&#39;def’,&#39;gh’) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>3、带分隔符连接函数：concat_ws<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select concat_ws(&#39;,&#39;,&#39;abc&#39;,&#39;def&#39;,&#39;gh&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>4、字符串截取函数：substr、substring<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select substr(&#39;abcde&#39;,3) from lxw_dual;</span><br></pre></td></tr></table></figure><br>返回字符串A从start位置到结尾的字符串</p>
<p>5、字符串转大写和小写：upper、ucase / lower、lcase<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select lcase(&#39;abSEd&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>6、去空格函数<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select trim(&#39; abc &#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>7、正则表达式替代函数：regexp_replcae<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select regexp_replace(&#39;foobar&#39;, &#39;oo|ar&#39;, &#39;&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure></p>
<p>8、json解析函数：get_json_object<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">get_json_object(string json_string, string path)</span><br></pre></td></tr></table></figure></p>
<p>9、分隔字符串函数：split<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hive&gt; select split(&#39;abtcdtef&#39;,&#39;t&#39;) from lxw_dual;</span><br></pre></td></tr></table></figure><br>返回数组</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>linux之shell</title>
    <url>/2020/04/18/linux%E4%B9%8Bshell/</url>
    <content><![CDATA[<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$# 是传给脚本的参数个数</span><br><span class="line">$0 是脚本本身的名字</span><br><span class="line">$1 是传递给该shell脚本的第一个参数</span><br><span class="line">$2 是传递给该shell脚本的第二个参数</span><br><span class="line">$@ 是传给脚本的所有参数的列表</span><br><span class="line">$* 是以一个单字符串显示所有向脚本传递的参数，与位置变量不同，参数可超过9个</span><br><span class="line">$$ 是脚本运行的当前进程ID号</span><br><span class="line">$? 是显示最后命令的退出状态，0表示没有错误，其他表示有错误</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>1、if-then语句<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if test command</span><br><span class="line">then commands</span><br><span class="line">else commands</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<p>test检测：<br>数字<br>n1 -eq n2     检查n1是否与n2相等<br>n1 -ge n2     检查n1是否大于或等于n2<br>n1 -gt n2     检查n1是否大于n2<br>n1 -le n2     检查n1是否小于或等于n2<br>n1 -lt n2     检查n1是否小于n2<br>n1 -ne n2     检查n1是否不等于n2</p>
<p>字符串<br>-n str1       检查str1的长度是否非0<br>-z str1       检查str1的长度是否为0</p>
<p>2、for循环<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for var in list do</span><br><span class="line">commands</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>例子：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file&#x3D;“states”</span><br><span class="line">IFS&#x3D;$&#39;\n’   #能读空行的值</span><br><span class="line">for state in $(cat $file)</span><br><span class="line">do</span><br><span class="line">   echo &quot;Visit beautiful $state&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>跳出循环：break、continue</p>
<p>3、创建函数<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">function name &#123; commands</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>高级函数<br>4、sed命令<br>Sed编辑器被称为流编辑器，与普通的交互式文本编辑器想法。<br>1）在命令行定义编辑器<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ Echo “this is a test” | sed ’s&#x2F;test&#x2F;big test’</span><br></pre></td></tr></table></figure><br>This is a big test<br>或者<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sed ’s&#x2F;dog&#x2F;cat&#x2F;‘ data.txt</span><br></pre></td></tr></table></figure><br>Sed编辑器并不会修改文本文件的数据</p>
<p>2）在命令行使用多个编辑器<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sed -e ’s&#x2F;brown&#x2F;green&#x2F;; s&#x2F;dog&#x2F;cat’ data.txt</span><br></pre></td></tr></table></figure><br> 必须要用；分割</p>
<p>3）从文件中读取编辑器命令<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sed -f script1.sed datat.txt</span><br></pre></td></tr></table></figure></p>
<p>4）写入文件<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Sed ‘1,2w test.txt’ datat.txt</span><br></pre></td></tr></table></figure><br>将test.txt文件的前两行打印到data.txt文件中</p>
<p>5、awk命令</p>
<p>1）格式化输出<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">awk &#39;&#123;printf &quot;%-8s %-10s\n&quot;,$1,$4&#125;&#39; log.txt</span><br></pre></td></tr></table></figure></p>
<p>2）使用，分割<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">awk &#39;BEGIN&#123;FS&#x3D;&quot;,&quot;&#125; &#123;print $1,$2&#125;&#39;  log.txt</span><br></pre></td></tr></table></figure></p>
<p>3）条件语句<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">awk &#39;BEGIN &#123;</span><br><span class="line">    num &#x3D; 11; </span><br><span class="line">    if (num % 2 &#x3D;&#x3D; 0) printf &quot;%d 是偶数\n&quot;, num; </span><br><span class="line">    else printf &quot;%d 是奇数\n&quot;, num </span><br><span class="line">&#125;&#39;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>谈谈我的北漂</title>
    <url>/2020/04/17/%E8%B0%88%E8%B0%88%E6%88%91%E7%9A%84%E5%8C%97%E6%BC%82/</url>
    <content><![CDATA[<p>最初开通github是打算写点技术文章，现在更像是我的记事本，时不时也需要记录下我对生活的感悟。<br>谈到北漂，以前一直以为与我无关，是很虚无飘渺的东西，因为我的目标城市是深圳或者上海。没想到阴差阳错最终来到北京。从去年19年的7月开始，我正式开启了我的北漂之旅，再过两个月就整整一年了。在这里我挥洒汗水，耗费青春的光阴而碌碌无为，忙忙碌碌且无成长，我常痛恨这样的自己。<br><a id="more"></a></p>
<h1 id="工作篇"><a href="#工作篇" class="headerlink" title="-工作篇 -"></a>-工作篇 -</h1><p>我工作的地方是被誉为中国互联网届的摇篮村，名叫后场村。我居住的地方也是人均程序员密度最高的西二旗。和我一起居住的还有我的两个研究生同学，和一个同事。另外还有一个是我校友的同事，一共五个人同租，后来成为我校友的女朋友，那是后话了。刚开始工作的三个月中，确实我成长最快的时候，这里要实名感谢@彩旭对我的帮助，我要是有计算机的问题基本都去找他，他也乐意帮忙，在他的帮助下，我才能快速上手linux，这个博客也是在他的影响下而开通的。而在业务层面，@子鹏对我的帮助较大。总之，前三个月是成长最快的时候，后续的工作其实都是在重复工作，没有自己的想法，只是一味地执行领导交代的任务。刚来这家公司最让我不习惯的是，内部没有很明确对校招生的培养机制，前辈写分享文档的也很少，所以需要自己一点点去琢磨，我想要是部门有完善的培养机制，应该能让我更快地上手吧。还有一个让我比较诡异的事情是。内部的分享沟通会很少，每个小组都在埋头干自己的工作，小组之间比较少交流，而且甚至部分小组藏着掖着，不想让其他组知道自己所做的事情，其他小组也无从介入，以保证自己的一个项目的绝对领导地位。<br>其他方面，由于部门是风控部门，是整个信贷产品的核心。所以，接触的面会广一些，会进行跨部门协同。这一块，需要不断地扯皮，才能推动业务进展，不过这一块，我想其他公司也该差不多吧。<br>公司的问题之下，也同时暴露了我的问题了，在工作中很粗心，经常计算出错，对待工作比较散漫，效率低下。这一块还是需要不断地磨合自己，历练自己。</p>
<h1 id="生活篇"><a href="#生活篇" class="headerlink" title="-生活篇-"></a>-生活篇-</h1><p>前面谈到我们是5个人同租房子。正所谓有人的地方就有江湖，从一开始的其乐融融，一片欢声笑语，到最后充满矛盾，相见无言，前后不超过2个月。这一切的导火索就是其中两人相恋了，矛盾不可避免地出现了。比如，本来约好5个人一起吃饭和游玩的计划。因为这对恋人私下约会而泡汤；又如，处于热恋期的两人常常在客厅聊至凌晨两三点，我们受其困扰，辗转难眠。从一开始的时候，搭伙煮饭，到最后分为三个团体，时间协调也是矛盾重重，所幸，我基本只点外卖。到最后，我悟出了一个道理，千万别和情侣一起合租。</p>
<p>十一将至，各种生活工作都开始稳定，就出现了一件大事，由于我们是5人合租，其中有两间是隔断房。而正值十一期间，北京严查隔断出租屋，导致大量中介的隔断房被拆除，我们门口就贴着一张隔断房拆除的通知。当时我们5人的关系还算不错，不像现在这样撕破脸都无所畏惧。我们惶恐不已，要是隔断房被拆除，无法再找个房子可以5个人合租在一起。为此我们不断地和房东沟通和交流，甚至做好了重新找房的准备。后来虽然证明这种担心是徒劳的，但我们还是费了不少心血在这上面。不过，我想我以后应该不会再租隔断房了。</p>
<h1 id="个人篇"><a href="#个人篇" class="headerlink" title="-个人篇-"></a>-个人篇-</h1><p>生活总是充满了各种感悟，北漂将近一年，已打算背起行囊，重新出发。<br><img src="/2020/04/17/%E8%B0%88%E8%B0%88%E6%88%91%E7%9A%84%E5%8C%97%E6%BC%82/12013139.jpg" alt="附图"></p>
]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>感悟</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>模型评估</title>
    <url>/2020/04/05/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>评分卡</title>
    <url>/2020/04/05/%E8%AF%84%E5%88%86%E5%8D%A1/</url>
    <content><![CDATA[<p>评分卡又称A卡，在金融领域，尤其是银行利用最多的模型，经常运用到贷前准入环节。它具有可解释性，模型稳定等各种优势。<br><a id="more"></a><br>得到评分卡的步骤如下：<br>一、认清目标<br>我们的目标是预测用户为好人的概率，并将概率转换成打分形式。分数越高表示用户的资质越好。</p>
<p>二、数据清洗和数据加工<br>将我们的非结构数据转化成结构化数据，连续数据转离散数据，去除异常值，标准化处理（最大最小值；正态标准化等）；<br>分箱操作就是将连续数据转成离散数据的方法之一。分箱的优势为：1、排除异常值的影响，例如：年龄为200岁；2、可以防止模型过拟合；3、为模型引入非线性，提高表达能力<br>分箱方法：</p>
<ul>
<li>监督方法：卡方分箱法、IV最大化分箱法</li>
<li>无监督方法：k-means聚类、等频、等宽</li>
</ul>
<p>三、特征工程<br>得到相对多的特征变量，在得到IV值之前，需要进行WOE，即特征转换。<br>之后分别计算IV值（information value），计算IV值。<br>根据IV值大小排列，IV值越高代表单个变量的可解释性越高。<br>得到比较重要的特征，取前topN特征代入线性回归中。<br>IV&lt;=0.02，没有解释性<br>0.1&lt;=IV&lt;0.02，具有较弱的解释性<br>0.3&lt;=IV&lt;=0.1，具有较强的解释性<br>0.3&lt;=IV，具有极强的解释性<br>一般来说，IV大于0.1时候，特征就可以保留下来。</p>
<p>四、LR线性回归<br>普通线性回归为：y = \beta_1<em>x_1+\beta_2</em>x_2+…+\beta_n<em>x_n，而logistic回归是将普通线性回归映射到 [0,1] 范围内。<br>Logistic 函数为：f(x) = \frac{1}{1+e^-x}<br>假定P是用户为坏人的概率，则1-P是用户为好人的概率，P∈[0,1]。<br>P(y=1|x) = \frac{e^wx}{1+e^wx}  ….. (1)<br>P(y=0|x) = \frac{1}{1+e^wx}        ……(2)<br>则 ods = \frac{p}{1-p}，是坏人与好人的几率。令p=P(y=1|x)，则好人的概率为1-p<br>将公式1除以公式2可得，ln\frac{p}{1-p} = wx，令y= ln\frac{p}{1-p}<br>故 lny = w_1</em>x_1+w_2<em>x_2+…+w_n</em>x_n</p>
<p>目标函数（损失函数）：<br>这里我们利用极大似然估计来得到logistic回归的损失函数：<br>L = \prod{I=1}{N}p^y_i+(1-p)^(1-y_i) ，<br>则lnL<br>        =  \sum{I=1}{N}ylnp+(1-)yln(1-p)<br>        =  \sum{I=1}{N}yln\frac{p}{1-p}+ln(1-p)<br>        =  \sum{I=1}{N}ywx+ln(\frac{1}{1+e^wx})</p>
<p>如何使损失函数最小化，这个时候就需要利用坐标下降法，来得到各个特征系数的值。</p>
<p>五、得到评分卡<br>在第四步，我们得到坏人的概率之后，就需要将概率转换成我们所需要的分数。<br>在得到分数之前，我们需要定义三个参数：</p>
<ul>
<li>基准odds好坏比，即\frac{p}{1-p}</li>
<li>基准分数</li>
<li>PDO(points to Double the odds)：当odds增加两倍时，所减少的信用分<br>可以列式子：</li>
</ul>
<ol>
<li>Base_score = A - Bln(odds)</li>
<li>Base_score - PDO = A - Bln(2odds)<br>可以得到：A = base_score + frac{PDO}{ln(2)}*ln(odds)，B = frac{PDO}{ln(2)}<br>当我们希望信用分为600分时，对应的ods为1:50。当ods扩大为2:50时，信用分降低20分至580分(PDO=20)，可以求出AB的取值。<br>A=487.122 ，B=28.854<br>六、模型评估<br>详见《模型与策略评估》专栏。</li>
</ol>
<p>参考目录：<br>【1】《统计学习方法》-李航<br>【2】《机器学习》-周志华</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>LR</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux基本操作指令</title>
    <url>/2020/04/05/Linux%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%E6%8C%87%E4%BB%A4/</url>
    <content><![CDATA[<p>一，注销，关机，重启<br>1、Logout 注销是登陆的相对操作，登陆系统后，若要离开系统，用户只要直接下达<br>logout 命令即可：<br>2、关机或重新启动的 shutdown 命令：<br>    －h 参数让系统立即关机<br>        shutdown –h now ← 要求系统立即关机；<br>        shutdown now ← 立刻关机；<br>        shutdown +5 ← 5 分钟后关机；<br>        shutdown 10:30 ← 在 10：30 时关机；<br>    －r 参数设置关机后重新启动<br>        shutdown -r now ← 立刻关闭系统并重启；<br>        shutdown -r 23:59 ← 指定在 23：59 时重启动；<br><a id="more"></a><br>3、重新启动计算机的 reboot 命令：<br>     -f 参数：不依正常的程序运行关机，直接关闭系统并重新启动计算机；<br>     -I 参数：在在重新启动之前关闭所有网络接口；<br>     虽然 reboot 命令有个参数可以使用，但是一般只需要单独运行 reboot 命令就可以了<br>二，文件与目录的操作<br>1、列出文件列表的 ls 命令<br>    ls：显示当前目录的内容；<br>    ls –a： 当运行 ls 命令时，并不会显示名称以“.”开头的文件。因此可加上“-a”参数指<br>定要列出这些文件；<br>    ls –s –S：以“-s”参数显示每个文件所有的空间，并以“-S”参数指定按所有占用空间的大<br>小排序；<br>    ls –l/usr/games：在 ls 命令后直接加上欲显示的目录路径，就会列出该目录的内容；<br>2、切换目录的 cd 命令<br>     cd tony ← 切换到当前目录下的 tony 子目录；<br>     cd .. ← 切换到上一层目录；<br>     cd / ← 切换到系统根目录；<br>     cd /usr/bin ← 切换到/usr/bin 目；<br>3、创建目录的 mkdir 命令<br>     mkdir tool：在目录下创建 tool 子目录<br>4、删除目录的 rmdir 命令<br>     rmdir tool ← 删除 tool 目录<br>5、复制文件的 cp 命令<br>     cp data1.txt data2.txt ← 将 data1.txt 复制成 data2.txt；<br>     cp data3.txt /tmp/data ← 将 data3 复制到/tmp/data 目录中；<br>    加入-v 参数可显示命令执行过程：<br>         cp zip.txt zip2.txt ← 一般状态下不会显示复制过程；<br>         cp –v zip.txt zip3.txt ← 以-v 显示复制过程；<br>    加入“-R”参数可同时复制目录下的所有文件及子目录：<br>         cp –v –R <em> backup ← 将所有文件（含子目录文件）复制到 backup 目录<br>6、删除文件或目录的 rm 命令<br>         rm myfile ← 删除指定的文件；<br>         rm </em> ← 删除当前目录中的所有文件；<br>    使用-f 参数时，rm 命令会直接删除文件，不再询问：<br>        rm –f <em>.txt ← 强迫删除文件；<br>    -r 也是一个相当常用的参数，使用此参数可同时删除指定目录下的所有文件及子目录<br>        rm –r data ← 删除 data 目录（含 data 目录下所有文件和子目录）；<br>        rm –r </em> ← 删除所有文件（含当前目录所有文件，所有子目录和子目录下的文件）<br>    使用-rf 参数，系统将直接删除该目录中所有的文件及子目录，不再询问。<br>         rm –rf tmp 强制删除 tmp 目录及该目录下所有文件及子目录；<br>7、让显示画面暂停的 more 命令<br>         ls –al more：当使用 ls 命令查看文件列表时，若文件太多则可以配合 more 命令使用；<br>         more data.txt： 单独使用 more 命令时，可用来显示文字文件的内容；<br>8、连接文件的 cat 命令<br>    cat命令可以显示文件的内容（经常和 more 命令搭配使用），或是将数个文件合并成一个文件<br>         cat preface.txt more：逐页显示 preface.txt 的内容；<br>         cat preface.txt &gt;&gt; outline.txt： preface.txt 附加到 outline.txt 文件之后；<br>         cat new.txt info.txt &gt;readme.txt：将 new.txt 和 info.txt 合并成 readme.txt 文件<br>    一次显示整个文件：<br>        cat filename<br>9、移动或更换文件，目录名称的 mv 命令<br>    mv（move）命令可以将文件及目录移动到另一个目录下面，或更换文件及目录的名称<br>        mv a.txt .. ← 将 a.txt 文件移到上层目录<br>        mv z1.txt z3.txt ← 将 z1.txt 改名成 z3.txt<br>         cd.. ← 切换到上一层目录<br>        mv backup.. ← backup 目录上移一层<br>10、显示当前所在目录的 pwd 命令<br>    pwd(print working directory)命令可显示用户当前所在的目录<br>11、查找文件的 locate 命令<br>    locate 命令可用来搜索包含指定条件字符串的文件或目录<br>         locate zh_CN 列出所有包含“zh_CN”字符串的文件和目录<br>12、搜索字符串得 grep 命令<br>    grep 命令可以搜索特定字符串来并显示出来<br>         grep text <em>.conf ← 搜索当前目录中扩展名为.conf 且包含“text”字符串；<br>        grep:amd.conf: ← 拒绝不符权限得操作；<br>        grep:diskcheck.conf: ← 拒绝不符权限得操作；<br>        grep:grub.conf ← 拒绝不符权限得操作；<br>        grep –s text </em>.conf：拒绝不符权限的操作之类的错误信息，可使用-s 参数消除<br>13、重导与管道<br>    “&gt;”可将结果输出到文件中，该文件原有的内容会被删除：“&gt;&gt;”则将结果附加到文件中，原文件内容不<br>会被清除<br>         ls –a&gt;dir.txt ← 将 ls –a 命令执行结果输出到 dir.txt 文件；<br>         cat data1.txt &gt;&gt; data2.txt ← 将 data1.txt 内容附加到 data2.txt 文件之后。<br>    通道(pipe)命令的符号是“ ”，可将某命令的结果输出给另一命令<br>         ls gerp conf ← 搜索并显示 ls 命令运行结果中包含有“conf”字符串；<br>         yes rm –r mydir：在删除文件或目录的时，可以利用 yes 命令重复输出“y”字符的特性，将结果传给 rm<br> 命令，如此即可避免重复输入“y”<br>14、Linux文件内容查看</p>
<ul>
<li>Cat 由第一行开始显示文件内容</li>
<li>Tac 从文件最后一行开始显示</li>
<li>Nl 显示的时候，顺道输出行号！</li>
<li>more一页一页的显示文件内容</li>
<li>less与more类似，但是比more更好的是，他可以往前翻页</li>
<li>head只看头几行</li>
<li>tail只看尾巴几行<br>三、打包、压缩与解压缩<br>1、打包文件的 tar 命令<br>tar 命令位于/bin 目录中，它能将用户所指定的文件或目录打包成一个文件<pre><code>  -c：创建一个新的 tar 文件；
   -v：显示运作过程信息；
   -f：在：指定文件名称；
   -z：调用 gzip 压缩命令执行压缩；
   -j：调用 bzip2 压缩命令执行压缩；
  -t：参看压缩文件内容；
  -x：解开 tar 文件
           tar cvf data.tar * ← 将目录下所有文件打包成 data.tar；
           tar cvf data.tar.gz * ← 将目录所有文件打包成 data.tar 再用 gzip 命令压缩；
           tar tvf data.tar * ← 查看 data.tar 文件中包括了哪些文件；
           tar xvf data.tar * ← 将 data.tar 解开
</code></pre>2、压缩与解压缩<br>  使用-z 参数来解开最常见的.tar.gz 文件：<pre><code>   tar –zxvf foo.tar.gz ←将文件解开至当前目录下
</code></pre>  使用-j 参数解开 tar.bz2 压缩文件：<pre><code>   tar –jxvf linux-2.4.20tar.bz2 ←将文件解开至当前目录下
</code></pre>   使用-Z 参数指定以 compress 命令压缩：<pre><code>   tar –cZvf prcture.tar.Z*.tif 将该目录下所有.tif 打包并命令压缩成.tar.Z文件
</code></pre>四：其他常用命令<br>1、修改密码的 passwd 命令<br>  passwd（password）命令可让用户变更密码<br>2、创建引导盘的 mkbootdisk 命令<br>  利用 mkbootdisk 命令创建一张新的引导盘：<pre><code>   mkbootdisk ‘uname -r
</code></pre>3、显示与设置时间的 date、clock 和 ntpdate 命令<br>  date 命令可以显示当前日期时间；<br>  clock 命令也可以显示出系统当前的日期与时间；<pre><code>   date 09091200 ← 将时间设定为 9 月 9 日 12 点 00 分；
   ntpdate stdtime.microsoft.com ← 与微软校时服务器校时；
   clock –w：这样下次启动时才会使用更改过的时间
</code></pre></li>
</ul>
<p>环境变量的查看</p>
<p>1、使用echo命令查看单个环境变量。例如：<br>echo $PATH<br>2、使用env查看所有环境变量。例如：<br>env<br>3、使用set查看所有本地定义的环境变量</p>
<p>杀死正在进行或已经是DEST状态的进程<br>        ps -aux：查看所有进程<br>        sudo kill PID：杀死相对应的PID号码<br>文件查看<br>使用wc命令 具体通过wc —help 可以查看。</p>
<ul>
<li>wc -l filename 就是查看文件里有多少行；</li>
<li>wc -w filename 看文件里有多少个word；</li>
<li>wc -L filename 文件里最长的那一行是多少个字。<br>wc命令<br>　　wc命令的功能为统计指定文件中的字节数、字数、行数, 并将统计结果显示输出。<br>　　语法：wc [选项] 文件…<br>　　wc同时也给出所有指定文件的总统计数。字是由空格字符区分开的最大字符串。该命令各选项含义如下：<br>　　- c 统计字节数。<br>　　- l 统计行数。<br>　　- w 统计字数。<br>　　这些选项可以组合使用。输出列的顺序和数目不受选项的顺序和数目的影响。总是按下述顺序显示并且每项最多一列。<br>　　行数、字数、字节数、文件名<br>　　如果命令行中没有文件名，则输出中不出现文件名。<br>　　例如：<br>　　$ wc - lcw file1 file2<br>　　4 33 file1<br>　　7 52 file2<br>　　11 11 85 total<pre><code>省略任选项-lcw，wc命令的执行结果与上面一样。
</code></pre>解压：<pre><code>  sudo tar -zxvf pip-6.0.8.tar.gz
  cd ~ 返回默认根目录
</code></pre>删除文件：<pre><code>  rm -f /var/log/httpd/access.log
</code></pre>删除文件夹：<pre><code>  rm -rf /var/log/httpd/access
</code></pre>查看指令：<pre><code>  1、date —help
  2、man date
</code></pre></li>
</ul>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title>python高级编程</title>
    <url>/2020/04/02/python%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/</url>
    <content><![CDATA[<h1 id="1、filter函数-过滤"><a href="#1、filter函数-过滤" class="headerlink" title="1、filter函数-过滤"></a>1、filter函数-过滤</h1><p>可以查看下面的例子<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">num = [<span class="number">1</span>,<span class="number">4</span>,<span class="number">-5</span>,<span class="number">3</span>,<span class="number">-7</span>,<span class="number">6</span>]</span><br><span class="line">after_filter = map(<span class="keyword">lambda</span> x:x**<span class="number">2</span>,filter(<span class="keyword">lambda</span> x:x&gt;<span class="number">0</span>,num))</span><br><span class="line">print(after_filter)</span><br></pre></td></tr></table></figure><br>当然，也可以用python自带的迭代器,可以达到一样的效果<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">after_filter = [x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> num <span class="keyword">if</span> x&gt;<span class="number">0</span>]</span><br></pre></td></tr></table></figure><br><a id="more"></a><br>此外，还可以使用生成器<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squre_generator</span><span class="params">(parameter)</span>:</span></span><br><span class="line">    rerurn(x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> num <span class="keyword">if</span> x&gt;parameter)</span><br><span class="line">g = list(squre_generator(<span class="number">0</span>))</span><br></pre></td></tr></table></figure></p>
<h1 id="2、装饰器"><a href="#2、装饰器" class="headerlink" title="2、装饰器"></a>2、装饰器</h1><p>装饰器为我们提供了一个增加已有函数或类的功能。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timethis</span><span class="params">(func)</span>:</span></span><br><span class="line"><span class="meta">   @wraps(func)</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">wrapper</span><span class="params">(*args,**kwargs)</span>:</span></span><br><span class="line">      start = time.time()</span><br><span class="line">      result = func(*args,**kwargs)</span><br><span class="line">      end = time.time()</span><br><span class="line">      print(func.__name__,end-start)</span><br><span class="line">      <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@timethis</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">countdown</span><span class="params">(n)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> n&gt;<span class="number">0</span>:</span><br><span class="line">    n-=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">countdown(<span class="number">10000</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="3、-和和xx-的区别"><a href="#3、-和和xx-的区别" class="headerlink" title="3、_和和xx__的区别"></a>3、_和<strong>和</strong>xx__的区别</h1><h2 id="1）“-”单下划线"><a href="#1）“-”单下划线" class="headerlink" title="1）“_”单下划线"></a>1）“_”单下划线</h2><p>可以在类的方法或属性前加一个“_”单下划线，意味着该方法或属性不应该去调用。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_method</span><span class="params">(self)</span>:</span> </span><br><span class="line">        print(<span class="string">'约定为不在类的外面直接调用这个方法，但是也可以调用’) </span></span><br><span class="line"><span class="string">    def method(self): </span></span><br><span class="line"><span class="string">        return self._method() </span></span><br><span class="line"><span class="string">a = A()</span></span><br></pre></td></tr></table></figure><br>在类A中定义了一个_method方法，按照约定是不能在类外面直接调用它的，为了可以在外面使用_method方法，又定义了method方法，method方法调用_method方法。请看代码演示：<br>a._method() 不建议在类的外面直接调用这个方法，但是也可以调用。最好是a.method()</p>
<h2 id="2）双”-”下划线"><a href="#2）双”-”下划线" class="headerlink" title="2）双”__”下划线"></a>2）双”__”下划线</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__method</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'This is a method from class A'</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">method</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.__method()</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">B</span><span class="params">(A)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__method</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">'This is a method from calss B'</span>)</span><br></pre></td></tr></table></figure>
<p>在类A中，<strong>method方法其实由于name mangling技术的原因，变成了_A</strong>method，所以在A中method方法返回的是_A<strong>method，B作为A的子类，只重写了</strong>method方法，并没有重写method方法，所以调用B中的method方法时，调用的还是_A<strong>method方法：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">27</span>]: a = A()</span><br><span class="line">In [<span class="number">28</span>]: b = B()</span><br><span class="line">In [<span class="number">29</span>]: a.method()</span><br><span class="line">This <span class="keyword">is</span> a method <span class="keyword">from</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br><span class="line"><span class="class"><span class="title">In</span> [30]:</span> b.method()</span><br><span class="line">This <span class="keyword">is</span> a method <span class="keyword">from</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span></span><br></pre></td></tr></table></figure><br>在A中没有</strong>method方法，有的只是_A__method方法，也可以在外面直接调用，所以python中没有真正的私有化</p>
<h2 id="3）“xx”前后各双下划线"><a href="#3）“xx”前后各双下划线" class="headerlink" title="3）“xx”前后各双下划线"></a>3）“<strong>xx</strong>”前后各双下划线</h2><p>在特殊的情况下，它只是python调用的hook。例如，<strong>init</strong>()函数是当对象被创建初始化时调用的;<strong>new</strong>()是用来创建实例。<br><strong>init</strong> #构造初始化函数,<strong>new</strong>之后运行<br><strong>new</strong> #创建实例所需的属性<br><strong>class</strong> #实例所在的类，实例.<strong>class</strong><br><strong>str</strong> #实例的字符串表示，可读性高<br><strong>repr</strong> #实例的字符串表示，准确性高<br><strong>del</strong> #删除实例引用<br><strong>dict</strong> #实力自定义属性，vars(实例.<strong>dict</strong>)<br><strong>doc</strong> #类文档，help(类或者实例)<br><strong>bases</strong> #当前类的所有父类<br><strong>getattribute</strong> #属性访问拦截器。</p>
<h1 id="4、map函数"><a href="#4、map函数" class="headerlink" title="4、map函数"></a>4、map函数</h1><p>map()函数接收两个参数，一个是函数，一个是序列，map将传入的函数依次作用到序列的每个元素，并把结果作为新的list返回。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></span><br><span class="line"><span class="meta">... </span><span class="keyword">return</span> x * x</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>map(f, [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>])</span><br></pre></td></tr></table></figure></p>
<h1 id="5、reduce函数"><a href="#5、reduce函数" class="headerlink" title="5、reduce函数"></a>5、reduce函数</h1><p>reduce这个函数必须接收两个参数，reduce把结果继续和序列的下一个元素做累积计算，其效果就是：<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="function"><span class="keyword">def</span> <span class="title">fn</span><span class="params">(x, y)</span>:</span></span><br><span class="line"><span class="meta">... </span><span class="keyword">return</span> x * <span class="number">10</span> + y</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>reduce(fn, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line"><span class="number">13579</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>编程</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>向左走，向右走</title>
    <url>/2020/03/30/%E5%90%91%E5%B7%A6%E8%B5%B0%EF%BC%8C%E5%90%91%E5%8F%B3%E8%B5%B0/</url>
    <content><![CDATA[<p>很喜欢台湾作家几米画的单行本漫画《向左走，向右走》，文字中处处透露着温暖，插画清新自然，很舒服。<br><a id="more"></a><br>书中描绘着，在一座陌生的城市中，寂寞孤独的一对男女因为偶然一次缘分在公园相遇，互诉衷肠，两个落寞的心彼此感受着对方的温暖。然而，天空开始下着暴雨，俩人不得不分开，在临别前女生给男生留下写着电话的字条，就各自匆忙回家。不幸的是，字条由于雨水打湿而模糊了字迹，辨认不出号码。女生就这么焦急地等待男生的电话，而男生由于打湿字条而懊悔，满怀希望去公园等待，每次只能失望而归。时间缓缓流逝，又回到当初孤生一人的状态，生活仿佛又恢复了平静，只有他们自己知道，他们的心结了厚厚一层霜。生活在同个城市，两人有很多次机会相遇，但一人习惯向左，一人习惯向右，总是插肩而过，仿佛命运给他们开了无情的玩笑，注定无法相遇。又过了一段时间，女生打算离开这个让她伤心的城市。女生早早起床，把行李收拾好，打算在日出来临之时逃离这座城市，恰好遇上同样外出的男生。这一次，命运开始重新眷顾他们，在最重要的时刻他们重新相遇，那一刻，初升的阳光温柔地打在他们身上，暖暖的，融化了心里的霜。<br><img src="/2020/03/30/%E5%90%91%E5%B7%A6%E8%B5%B0%EF%BC%8C%E5%90%91%E5%8F%B3%E8%B5%B0/left.jpg" alt="漫画图"><br>这本书其实带给我很深的感动。以前在学校，身边总是围绕着很多东西，心里不觉得孤单，但等我真正走出社会，我才发现，在这钢筋水泥包裹着的城市，心慢慢开始学会忍受孤独。慢慢地开始习惯一个人，习惯一个人吃饭、一个人逛街、一个人看电影，一个人学会忍受孤独，内心开始慢慢封闭，终于我们会发现原来一个人也会慢慢习惯。</p>
<p>本书带给我的另一个感受是，人的一生会错过许许多多的人，有的人你会跟他相识相知，然后一别再也不见；有的人仅仅是打一个照面，就再也没有出现在你的世界中。每一天我们都在上演这离别戏码，可能是你身边的爱人和家人，也有可能是司机、路人、乘客。每次离别时，我们总以为还有机会再见，下次会有勇气把“我喜欢你”说给心底的那人听，但往往离别之后，再也无法遇见，未说出口的表白成为永久的遗憾。</p>
<p>一别之后，两地相悬，怎知说那三四载，谁知是一生憾事。</p>
]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>感悟</tag>
        <tag>杂文</tag>
      </tags>
  </entry>
  <entry>
    <title>高性能MySQL</title>
    <url>/2020/03/21/%E9%AB%98%E6%80%A7%E8%83%BDMySQL/</url>
    <content><![CDATA[<p>浅谈高性能MySQL</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>投资的那些事</title>
    <url>/2020/03/15/%E6%8A%95%E8%B5%84/</url>
    <content><![CDATA[<p>人的一生都是不断投资自己的一个过程，投资是一辈子的事情，任何人都应该去学会投资。这里的投资并不是狭隘地指投资股票、债券等二级市场的行为，它也可以掌握理财或者更单纯地投资自己，花费时间看我一本书是投资、投入精力学习一项新技术也是投资。对于投资，我有几点想法，可以和大家一起交流。</p>
<a id="more"></a>
<h2 id="1、任何时候，投资的首要目标都是先投资自己"><a href="#1、任何时候，投资的首要目标都是先投资自己" class="headerlink" title="1、任何时候，投资的首要目标都是先投资自己"></a>1、任何时候，投资的首要目标都是先投资自己</h2><p>为什么投资的首要目标是投资自己？不要认为投资都是将钱投到金融市场中，投资自己比其他任何投资都更有意义。那么该如何正确投资自己，每天保持不断学习，付出时间和精力，每天坚持看几本书，培养自己的兴趣爱好，和喜欢的人交谈，花钱培养一项新技能，这些都是可以让你受益匪浅的投资，将会伴随你的一生。任何适合，投资自己永远是一项正确的决定。投资自己，永远不要怕多晚。</p>
<h2 id="2、不断学习、努力工作"><a href="#2、不断学习、努力工作" class="headerlink" title="2、不断学习、努力工作"></a>2、不断学习、努力工作</h2><p>学习是最有价值的一项投资，这是一条准则。古今中外，莫不如是。不会学习的人，只会固步自封，止步不前，只停留在同一层思想到老，是很可悲的一件事。学习不仅可以使我们获得前人宝贵的经验，也可以让我们规避他们所犯过的错误，所谓以史明鉴。</p>
<p>现在的我们工作是为了获取原始的积累，只有足够的原始积累，你才能有资本去做你想做的事情。现在你努力工作是为了更好的明天。别抱怨工作，学会去接受它、喜欢它，或许你也可以在工作上实现你人生的价值。</p>
<h2 id="3、构建适合自己的投资逻辑"><a href="#3、构建适合自己的投资逻辑" class="headerlink" title="3、构建适合自己的投资逻辑"></a>3、构建适合自己的投资逻辑</h2><p>投资的门派很多，根据金融市场不同可以分为一级市场的PE、VC，和二级市场流通市场；根据产品的不同可以分为债券、股票、汇率、期权、期货等派别；按照投资行为又分为投资者、投机者、套利者。在这纷扰繁杂的金融市场中，要构建属于自己的投资逻辑，形成自己的投资理念，否则随波逐流投机赚的钱，总又一天会以同样的形式流出。</p>
<h2 id="4、付诸实践，不断试错"><a href="#4、付诸实践，不断试错" class="headerlink" title="4、付诸实践，不断试错"></a>4、付诸实践，不断试错</h2><p>有人说，“年轻人要用于去尝试，不要害怕出错；到老了，犯错误的成本就会很高”。这句话是很有道理的，尤其是在投资界。年轻时，你的资本比较小，亏损了大不了，你还可以重新来过，你还年轻，还有大把的时间可以奋斗，但是当你老了，你已经没有能力或者精力去靠工作赚钱，这时候投资发生损失对于老年生活质量会大大打个折扣。所以，趁年轻，不断去试错，从失败中汲起教训，要么早点认清自己不适合投资，将时间放在更有价值、更合适的地方；要么坚持下去，不断修正自己的投资，完善投资框架，体验投资给你带来的财富增值。</p>
<p>附我的股票投资逻辑图：<br><img src="/2020/03/15/%E6%8A%95%E8%B5%84/invest.jpg" alt="逻辑图"></p>
]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>股市</tag>
        <tag>想法</tag>
      </tags>
  </entry>
  <entry>
    <title>关于股市的一些看法</title>
    <url>/2020/03/12/%E7%96%AB%E6%83%85-%E8%82%A1%E5%B8%82/</url>
    <content><![CDATA[<p>做坚定的价值投资者</p>
<p>最近，金融市场不太平。由于疫情影响，全球股市暴跌，债券、黄金、石油、期货期权一片低迷，截止到今日，美股更是触发两次熔断，恐慌指数维持在20以上。一时间，整个金融市场一遍哀嚎，空者的天堂，多者的地狱。正可谓风水轮流转，美股结束长达十几年的牛市，跌幅超过20%只用了短短两个星期。</p>
<a id="more"></a>
<p>虽然中国的疫情基本上整体得到控制，但是由于中国市场与全球经济的联动越发密切，A股不可避免地随全球指数暴跌。笔者的账户从原先20%的盈利大幅回撤到5%，或许可能把盈利给抹平。但是，我想说要做坚定的价值投资者。巴菲特曾说过，要在别人贪婪的时候恐惧，恐惧的时候贪婪。前半部分，我自问没有做到，在前段时间A股技术型牛市时候，忽视国外疫情的发展，没有意识到风险，因此现在能做的只有后者。上证指数在3000点附近徘徊，有可能会继续下跌，但整体风险已经减弱，等到国外疫情稳定下来，就是A股突破的日子。</p>
<p>为什么要做坚定的价值投资者呢，纵观A股历史，只有白马股才能穿越牛熊。我们需要做只有不断丰富自己的知识、提高自己的投资水平，发现被低谷的白马股。</p>
]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>股市</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习-转</title>
    <url>/2020/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%BD%AC/</url>
    <content><![CDATA[<p>机器学习是计算机科学的一个子领域，在人工智能领域，机器学习逐渐发展成模式识别和计算科学理论的研究。从2016年起，机器学习到达了不合理的火热巅峰。但是，有效的机器学习是困难的，因为机器学习本身就是一个交叉学科，没有科学的方法及一定的积累很难入门。</p>
<a id="more"></a>
<h2 id="一．机器学习入门篇："><a href="#一．机器学习入门篇：" class="headerlink" title="一．机器学习入门篇："></a>一．机器学习入门篇：</h2><p>1、<a href="https://yq.aliyun.com/articles/67218?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">让你少走弯路：这有一份开展机器学习的简短指南</a></p>
<p>摘要：本文分享了一份简单的关于开展机器学习的心得体会，目的是给初学者提供基本的指导，主要讲解了建立系统、选择合适的评价指标、数据处理、系统优化等内容，帮助初学者少走一些弯路。</p>
<p>2、<a href="https://yq.aliyun.com/articles/204352?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">机器学习的入门“秘籍”</a></p>
<p>摘要：机器学习已经成为当下最火热的技术之一，对于初学者来说，如何快速入门机器学习是至关重要的。本文属于入门级宝典，高手请绕道！</p>
<p>3、<a href="https://yq.aliyun.com/articles/213634?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">会玩超级玛丽，机器学习能有多难?</a></p>
<p>摘要：小白也能看懂机器学习？这篇文章用超级玛丽的原理教会你，到底什么是机器学习，让尖端科技不再艰深难懂。</p>
<p>4、<a href="https://yq.aliyun.com/articles/168744?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">机器学习能为你的业务做什么？有些事情你肯定猜不到！第一篇</a></p>
<p>摘要：机器学习是一项令人难以置信的技术，你需要了解很多很多的基础知识，以使得业务功能尽可能的不受复杂算法的影响，让你能够提出正确的问题、了解机器学习模型开发过程、成立一个团队以促进学科间的不断合作，而不是把数据科学视为一个产生奇迹的黑匣子。</p>
<p>5、<a href="https://yq.aliyun.com/articles/169190?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">关于机器学习算法 你需要了解的东西 第二篇</a></p>
<p>摘要：对学习算法进行分类是基于构建模型时所需的数据：数据是否需要包括输入和输出或仅仅是输入，需要多少个数据点以及何时收集数据。根据上述分类原则，可以分为4个主要的类别：监督学习、无监督学习、半监督学习和强化学习。</p>
<p>6、<a href="https://yq.aliyun.com/articles/174724?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">如何开发机器学习模型？第三篇</a></p>
<p>摘要：创建一个优秀的机器学习模型跟创建其他产品是一样的：首先从构思开始，把要解决的问题和一些潜在的解决方案放在一起考虑。一旦有了明确的方向，就可以对解决方案进行原型化，然后对它进行测试以确定是否满足需求，不妨看看本文是如何一步一步实现的。</p>
<p>7、<a href="https://yq.aliyun.com/articles/175707?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">如何高效运作机器学习团队第四篇</a></p>
<p>摘要: 一个“传统”的产品团队由设计师、工程师和产品经理组成，而数据分析师有时也会包含在其中，但大多数情况下是多个团队共享这个稀缺资源。在机器学习团队中又会有哪些角色和组织结构呢，本文为你揭晓。</p>
<p>8、<a href="https://yq.aliyun.com/articles/178357?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">机器学习会产生哪些用户体验问题？第五篇</a></p>
<p>摘要：许多机器学习算法都是黑匣子：输入大量的数据，然后获得一个以某种神秘方式工作的模型。这使得很难向用户解释机器学习的结果。在许多算法中，还存在着交互效应，这使得模型更加难以解释了。你可以把这个看成是特征之间的复合效应，特征之间以多种奇怪而又复杂并且不为人类所理解的方式结合在一起，整体效应大于各个部分效应。</p>
<p>9、<a href="https://yq.aliyun.com/articles/67165?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">简单自学机器学习理论——引言 (Part I)</a></p>
<p>摘要：本篇文章是”机器学习理论”三部曲中的第一部分，主要介绍学习机器学习的动机及基本理论知识，详细介绍机器学习所学习的问题、泛化误差以及学习问题是否可解的公式化表示，为初步研究机器学习的人员介绍了机器学习的基本处理过程。</p>
<p>10、<a href="https://yq.aliyun.com/articles/67168?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">简单自学机器学习理论—— 泛化界限 (Part II )</a></p>
<p>摘要：本篇文章是”机器学习理论”三部曲中的第二部分，主要介绍独立同分布、大数法则及hoeffding不等式等基本数学知识，详细推导了泛化界限及其分解。</p>
<p>11、<a href="https://yq.aliyun.com/articles/67170?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">简单自学机器学习理论——正则化和偏置方差的权衡 (Part III )</a></p>
<p>摘要：本篇文章是”机器学习理论”三部曲中的第三部分，主要介绍方差分解以及目标函数的正则化，通过仿真可以看到，引入正则化项限定了学习问题的解决方案范围。</p>
<p>12、<a href="https://yq.aliyun.com/articles/78023?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">入门级攻略：机器学习 VS. 深度学习</a></p>
<p>摘要：本文以浅显易懂的语言介绍了机器学习和深度学习的定义及应用，以及在源数据要求，硬件支持，特征工程、问题解决方式、执行时间及可解释性等方面的区别，对于新手入门有很大启示意义。</p>
<p>13、<a href="https://yq.aliyun.com/articles/200980?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">增强学习小白？本文带你入门了解增强学习</a></p>
<p>摘要：入门一件新事物总是会有些无从下手的，看了本文希望可以给大家一些帮助和了解。</p>
<p>14、<a href="https://yq.aliyun.com/articles/66489?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">这10本由浅入深的好书，或让你成为机器学习领域的专家</a></p>
<p>摘要：机器学习是个跨领域的学科，而且在实际应用中有巨大作用，但是没有一本书能让你成为机器学习的专家。在这篇文章中，我挑选了10本书，这些书有不同的风格，主题也不尽相同，出版时间也不一样。因此，无论你是新手还是领域专家，定能找到适合你的。</p>
<p>15、<a href="https://yq.aliyun.com/articles/64929?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">想知道机器学习掌握的怎么样了吗？这有一份自测题（附答案和解析）</a></p>
<p>摘要：人类对于自动化和智能化的追求一直推动着技术的进步，而机器学习这类型的技术对各个领域都起到了巨大的作用。随着时间的推移我们将看到机器学习无处不在从移动个人助理到电子商务网站的推荐系统。即使作为一个外行你也不能忽视机器学习对你生活的影响。本次测试时面向对机器学习有一定了解的人。</p>
<p>16、<a href="https://yq.aliyun.com/articles/222864?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">送机器学习电子书——(TensorFlow)RNN入门</a></p>
<p>摘要：本文作者正在写自己的新书Machine Learning with TensorFlow，这篇博文只是他新书的一小部分，作者用简单的语言介绍了RNN，不用一个小例子介绍了如何使用Tensorflow中内置的RNN模型进行预测。</p>
<p>17、<a href="https://yq.aliyun.com/articles/221708?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">适合入门的8个趣味机器学习项目</a></p>
<p>摘要：还在为找不到机器学习入门练手项目而感到无奈吗？本指南中，将给大家带来8个适合初学者学习的有趣的机器学习项目，简单易学，相信会增添大家学习机器学习的信心。</p>
<p>18、<a href="https://yq.aliyun.com/articles/222434?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">机器学习快速入门：你必须知道的三大算法</a></p>
<p>摘要：每天霸占新闻头条的“机器学习”，想入门，先看懂这三大算法。</p>
<h2 id="二．机器学习算法篇："><a href="#二．机器学习算法篇：" class="headerlink" title="二．机器学习算法篇："></a>二．机器学习算法篇：</h2><p>1、<a href="https://yq.aliyun.com/articles/86632?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">快速选择合适的机器学习算法</a></p>
<p>摘要：机器学习初学者可以通过本文了解如何快速找到合适的机器学习算法。</p>
<p>2、<a href="https://yq.aliyun.com/articles/64245?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">多重角度解读：贝叶斯推理是怎么工作的</a></p>
<p>摘要：本文首先介绍了贝叶斯的起源，并利用简单的例子生动形象地讲解了贝叶斯定理是如何工作的，解释了其基本原理以及公式的物理含义。</p>
<p>3、<a href="https://yq.aliyun.com/articles/113512?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">简单通俗易懂：一个小例子完美解释Naive Bayes（朴素贝叶斯）分类器</a></p>
<p>摘要：Naive Bayes分类器的解释有很多，但是基于一个小例子来解释的不多，本文就是基于一个简单通俗易懂的小例子来解释Naive Bayes分类器。</p>
<p>4、<a href="https://yq.aliyun.com/articles/113511?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">“学”、“习”二合一：监督学习——支持向量机（SVM）入门</a></p>
<p>摘要：SVM是机器学习中有监督学习的一种，通常用来进行模式识别、分类、以及回归分析。本文用一个小例子简介SVM，言简意赅，通俗易懂。</p>
<p>5、<a href="https://yq.aliyun.com/articles/214305?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">机器学习利器——决策树和随机森林</a></p>
<p>摘要: 机器学习是当下最火的领域，本文通过一个小例子介绍了其核心算法：决策树和随机森林。</p>
<p>6、<a href="https://yq.aliyun.com/articles/63053?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">基于图的机器算法 （一）</a></p>
<p>摘要：基于图的机器算法学习是一个强大的工具。结合运用模块特性，能够在集合检测中发挥更大作用。</p>
<p>7、<a href="https://yq.aliyun.com/articles/65036?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">基于图的机器算法 （二）</a></p>
<p>摘要：基于图的机器算法学习是一个强大的工具。结合运用模块特性，能够在集合检测中发挥更大作用。本文是基于图的机器算法系列文的第二篇。</p>
<p>8、<a href="https://yq.aliyun.com/articles/66987?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">简单易学！一步步带你理解机器学习算法——马尔可夫链蒙特卡罗（MCMC）</a></p>
<p>摘要：对于简单的分布，很多的编程语言都能实现。但对于复杂的分布，是不容易直接抽样的。马尔可夫链蒙特卡罗算法解决了不能通过简单抽样算法进行抽样的问题，是一种实用性很强的抽样算法。本文将简明清晰地讲解马尔可夫链蒙特卡罗算法，带你理解它。</p>
<p>9、<a href="https://yq.aliyun.com/articles/66794?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">进阶隐式矩阵分解——探讨如何实现更快的算法</a></p>
<p>摘要：本文重点是围绕Conjugate Gradient（共轭梯度）方法来探讨更优的矩阵分解算法。</p>
<p>10、<a href="https://yq.aliyun.com/articles/73484?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">纯干货|机器学习中梯度下降法的分类及对比分析（附源码）</a></p>
<p>摘要：本文详细介绍了基于使用数据量的多少，时间复杂度以及算法准确率的不同类型的梯度下降法，并详细说明了3种梯度下降法的比较。</p>
<p>11、<a href="https://yq.aliyun.com/articles/68901?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">深度学习网络大杀器之Dropout（I）——深入解析Dropout</a></p>
<p>摘要：本文详细介绍了深度学习中dropout技巧的思想，分析了Dropout以及Inverted Dropout两个版本，另外将单个神经元与伯努利随机变量相联系让人耳目一新。</p>
<p>12、<a href="https://yq.aliyun.com/articles/110002?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">深度学习网络大杀器之Dropout（II）——将丢弃学习视为集成学习之我见</a></p>
<p>摘要：本文分析了可以将丢弃学习当作是集成学习。在集成学习中，可以将一个网络划分成若干个子网络，并且单独训练每个子网络。在训练学习后，将每个子网络的输出进行平均得到集成输出。另外，展示了丢弃学习可以看成是在每次迭代中不同隐藏节点集合的集成学习表现，同时也展示了丢弃学习有着与L2正则化一样的效果。</p>
<p>13、<a href="https://yq.aliyun.com/articles/73661?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">神经网络常用激活函数对比：sigmoid VS sofmax（附python源码）</a></p>
<p>摘要：本文介绍了神经网络中的两种常用激活函数——softmax与sigmoid函数，简单介绍了其基本原理、性质及其使用，并用python进行了实例化演示，在文章的最后总结了两种激活函数的区别。</p>
<p>14、<a href="https://yq.aliyun.com/articles/72738?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">新颖训练方法——用迭代投影算法训练神经网络</a></p>
<p>摘要：本文介绍了一种利用迭代投影算法对神经网络进行训练的方法，首先介绍了交替投影的基础知识，说明投影方法是寻找非凸优化问题解决方案的一种有效方法；之后介绍了差异图的基础知识，将差异图与一些其他算法相结合使得差分映射算法能够收敛于一个好的解决方案；当投影的情况变多时，介绍了分治算法，最后将迭代投影算法应用到神经网络训练中，给出的例子实验结果表明效果不错。</p>
<p>15、<a href="https://yq.aliyun.com/articles/71662?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">车辆追踪算法大PK：SVM+HOG vs. YOLO</a></p>
<p>摘要：本文通过SVM+HOG算法，YOLO算法实现车辆检测和跟踪准确性和速度的对比，得出YOLO算法更具优势的结论。</p>
<p>16、<a href="https://yq.aliyun.com/articles/69263?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">什么是视频向量化？本文带你了解基于DeepWalk的视频推荐</a></p>
<p>摘要：本文简要讲述了视频向量化，对DeepWalk的算法进行简单的解释。</p>
<p>17、<a href="https://yq.aliyun.com/articles/70733?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">比PCA降维更高级——（R/Python）t-SNE聚类算法实践指南</a></p>
<p>摘要: 本文介绍t-SNE聚类算法，分析其基本原理。并从精度上与PCA等其它降维算法进行比较分析，结果表明t-SNE算法更优越，本文最后给出了R、Python实现的示例以及常见问题。t-SNE算法用于自然语音处理、图像处理等领域很有研究前景。</p>
<p>18、<a href="https://yq.aliyun.com/articles/216164?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">随机森林 VS 梯度提升机——模型融合之我见</a></p>
<p>摘要：本文节选自Quora社区上“When would one use Random Forests over Gradient Boosted Machines (GBMs)?”问题的回答，几位博主就随机森林(Random Forests)与梯度提升机(Gradient Boosted Machines, GBMs)的适合场景以及优缺点展开了讨论。</p>
<h2 id="三．机器学习常用库："><a href="#三．机器学习常用库：" class="headerlink" title="三．机器学习常用库："></a>三．机器学习常用库：</h2><p>1、<a href="https://yq.aliyun.com/articles/69330?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">倚天遇到屠龙：LightGBM VS xgboost谁才是最强的梯度提升库？</a></p>
<p>摘要：很多人把XGBoost比作屠龙刀，LightGBM比作倚天剑，那么当倚天遇到屠龙，谁更强呢？</p>
<p>2、<a href="https://yq.aliyun.com/articles/81469?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">即学即用：Pandas入门与时间序列分析</a></p>
<p>摘要：这篇文章是Alexander Hendorf 在PyData Florence 2017上做的报告。报告前半部分主要为初学者介绍Pandas的基本功能，如数据输入/输出、可视化、聚合与选择与访问，后半部分主要介绍如何使用Pandas进行时间序列分析，源代码亲测可用。</p>
<p>3、<a href="https://yq.aliyun.com/articles/136493?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">俄罗斯最大搜索引擎Yandex开源了一款梯度提升机器学习库CatBoost</a></p>
<p>摘要：俄罗斯搜索巨头Yandex宣布，将向开源社区提交一款梯度提升机器学习库CatBoost。它能够在数据稀疏的情况下“教”机器学习。特别是在没有像视频、文本、图像这类感官型数据的时候，CatBoost也能根据事务型数据或历史数据进行操作。</p>
<p>4、<a href="https://yq.aliyun.com/articles/159746?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">Netflix开源面向稀疏数据优化的轻量级神经网络库Vectorflow</a></p>
<p>摘要：在Netflix公司，我们的机器学习科学家在多个不同的领域处理着各种各样的问题：从根据你的爱好来定制电视和推荐电影，到优化编码算法。我们有一小部分问题涉及到处理极其稀疏的数据；手头问题的总维度数很容易就能达到数千万个特征，即使每次要看的可能只是少数的非零项。</p>
<p>5、<a href="https://yq.aliyun.com/articles/210393?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">Python高性能计算库——Numba</a></p>
<p>摘要：在计算能力为王的时代，具有高性能计算的库正在被广泛大家应用于处理大数据。例如：Numpy，本文介绍了一个新的Python库——Numba， 在计算性能方面，它比Numpy表现的更好。</p>
<p>6、<a href="https://yq.aliyun.com/articles/68270?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">第二热门语言：从入门到精通，Python数据分析库大全</a><br>摘要：本文介绍了一些常见的用于数据分析任务的Python库，如Numpy、Pandas、Matplotlib、Scikit-learn以及BeautifulSoup等，这些工具库功能强大，便于上手。有了这些帮助，数据分析会变得分外简单。</p>
<p>7、<a href="https://yq.aliyun.com/articles/158384?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">新工具——TensorLayer：管理深度学习项目的复杂性</a></p>
<p>摘要：本文介绍了一种新基于TensorFlow的python库——TensorLayer，它能够有效的帮助开发者管理好自己的深度学习网络。并且它还提供了很多功能强悍的API，帮助开发者更好的完成任务。</p>
<p>8、<a href="https://yq.aliyun.com/articles/215295?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">Pandas并非完美无缺</a></p>
<p>摘要：我们一直使用Pandas，但是却不知道关于Pandas的细节。Pandas开发者深度复盘Pandas，指出了十大关键性问题，并通过介绍了如何使用Apache Arrow来解决这些问题。</p>
<p>9、<a href="https://yq.aliyun.com/articles/222523?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">关于Numba你可能不了解的七个方面</a></p>
<p>摘要：目前Numba正被开始流行使用来加速Python程序，本文讲解了七个大家可能不了解的方面，希望对大家有所帮助。</p>
<h2 id="四．机器学习实战篇："><a href="#四．机器学习实战篇：" class="headerlink" title="四．机器学习实战篇："></a>四．机器学习实战篇：</h2><p>1.57行价值八千万美元的车牌识别代码</p>
<p>摘要：为了防止被窃车辆进入黑市销售，警方使用了一个名为VicRoads的基于网络的服务，该服务用于检查车辆的登记状态。该警局还投资研发了一个固定式汽车牌照扫描器：一个固定的三脚架摄像头，可扫描过往的车辆，并自动识别被窃车辆。</p>
<p>2.如何利用机器学习预测房价？</p>
<p>摘要：本文作者利用自己过去三个月里所学到的东西，来预测所在城市的房价。所用到的技术有网络爬取技术、文本自然语言处理，图像上的深度学习模型以及梯度增强技术等。</p>
<p>3.机器学习中的技术债务</p>
<p>摘要：许多人遇到技术债务时都会眉头紧锁，但一般来说，技术债务并不是一件坏事。例如，当我们需要在最后期限之前发布版本的时候，技术债务就是一个可以利用起来的合理手段。但是技术债务存在与金融债务一样的问题，那就是到了要偿还债务的时候，我们所付出的要比开始时付出得多。这是因为技术债务具有复合效应。</p>
<p>4.DIY图像压缩——机器学习实战之K-means 聚类图像压缩：色彩量化</p>
<p>摘要：本文以图像压缩为例，介绍了机器学习的实际应用之一。</p>
<p>5.如何将机器学习用在基于规则的验证上</p>
<p>摘要：这篇文章介绍了一些高级问题，比如：智能自治系统的验证有多少可以用机器学习来实现？大多数的需求是否仍然是基于规则的，如果是这样，那么它们如何跟机器学习相结合？ 机器学习和规则之间的不稳定接口如何影响基于机器学习的系统？</p>
<p>6.Certigrad——随机计算图优化系统</p>
<p>摘要：Certigrad是一种概念证明，它是用于开发机器学习系统的一个新途径。</p>
<p>7.使用神经网络和遗传算法玩转 Flappy Bird</p>
<p>摘要：本文展示了针对Flappy Bird游戏设计的机器学习算法。本实验的目标是使用神经网络和遗传算法编写一个人工智能游戏控制器，打出游戏最高分，不服的来挑战！</p>
<p>8.教机器写代码：增强拓扑进化网络(NEAT)</p>
<p>摘要：NEAT的意思是“增强拓扑进化网络”，它描述了在进化过程中受遗传修饰启发的自学习机器的算法概念，不妨看看它是如何教机器写代码的。</p>
<ol>
<li>机器学习中，使用Scikit-Learn简单处理文本数据</li>
</ol>
<p>摘要：机器学习中，我们总是要先将源数据处理成符合模型算法输入的形式，比如将文字、声音、图像转化成矩阵。对于文本数据首先要进行分词（tokenization），移除停止词（stop words），然后将词语转化成矩阵形式，然后再输入机器学习模型中，这个过程称为特征提取（feature extraction）或者向量化（vectorization）。</p>
<h2 id="五．机器学习杂谈篇："><a href="#五．机器学习杂谈篇：" class="headerlink" title="五．机器学习杂谈篇："></a>五．机器学习杂谈篇：</h2><p>1.关于机器学习你必须了解的十个真相</p>
<p>摘要：作者从非专业人士的角度对人工智能常见的误解进行了解释说明。</p>
<p>2.谁更胜一筹？——随机搜索 V.S. 网格搜索</p>
<p>摘要：随机法和网格法都是常用的、有效的结构优化方法。那么它们两者当中谁更胜一筹呢？在本文中，作者通过有趣的地形搜索实验，找到了答案。</p>
<p>3.没有任何公式——直观的理解变分自动编码器VAE</p>
<p>摘要：本文简单介绍了变分自动编码器VAE的基本原理，从经典神经网络的贝叶斯计算概率方法慢慢转变到变分自动编码器神经网络中的优化问题，使用KL散度度量误差，给大家提供一个VAE的基本框架。全篇没有公式，通俗易懂。</p>
<p>4.增强避障系统设计浅析：站在机器学习的角度，剖析学习型避障小车的设计思路</p>
<p>摘要：FF91于12017年1月4日在美国拉斯维加斯成功首发，拉开了互联网生态电动汽车的序幕。自动泊车使得停车也成为了一种享受，新手司机再也不用担心该如何见缝插针了。但是如果在车水马龙的繁忙环境下，无人驾驶还能得心应手吗？本文将站在机器学习的角度和大家分享学习型避障小车的设计思路。</p>
<p>5.AlphaGo在围棋界成为最强王者后，我们该如何进行机器学习？</p>
<p>摘要：机器学习无疑是时下的科技热点。无人驾驶，机器下棋，股市预测等领域，我们都能找到机器学习忙碌和高大的身影。那么对于初学者来说，该如何下手？该怎么学习呢？</p>
<p>6.分享Andrew Ng在深度学习暑期班中演讲的机器学习项目</p>
<p>摘要：深度学习项目流程，带你走出迷茫。</p>
<p>7.分布式机器学习平台比较</p>
<p>摘要：机器学习，特别是深度学习（DL），最近已经在语音识别、图像识别、自然语言处理、推荐/搜索引擎等领域获得了成功。这些技术在自主驾驶汽车、数字卫生系统、CRM、广告、物联网等方面都存在着非常有前景的应用。当然，资金驱动着这些技术以极快的速度向前发展，而且，最近我们已经看到了有很多机器学习平台正在建立起来。</p>
<p>8.<a href="https://yq.aliyun.com/articles/187541?spm=a2c4e.11153940.0.0.a9c92664Gi6jmF" target="_blank" rel="noopener">机器学习和统计学的“爱恨情仇”可以结束了</a></p>
<p>摘要：机器学习和统计学在数据科学的领域里，已经相爱相杀很多年。今天，就让我们跟随ML从业者和统计学家两者组成团队，解开两者这几十年的“爱恨情仇”。</p>
<p>9.2017上半年无监督特征学习研究成果汇总</p>
<p>摘要：无监督学习是人工智能时代核心技术，今天我们就来盘点一下2017上半年无监督学习出现了那些重要的研究成果。</p>
<p>10.有监督相似性学习：基于相似问题数据的对称关系学习</p>
<p>摘要：本文简单介绍基于相似问题数据的对称关系学习，通过在Quora数据集和StackExchange语料库上应用孪生卷积神经网络的结果表明，对称网络能够较大幅度地提高检测精度。</p>
<p><strong>11.应用机器学习：传道解惑指南</strong></p>
<p>摘要：本文作者编辑了一份包括概念、定义、资源以及工具的知识合集，这对于在这个复杂领域从事工作的人来说非常有用。</p>
<p><a href="https://yq.aliyun.com/articles/221644?utm_content=m_33134" target="_blank" rel="noopener">本文原址</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>转发</tag>
      </tags>
  </entry>
  <entry>
    <title>FRM-之信用风险管理</title>
    <url>/2020/03/03/FRM-%E4%B9%8B%E4%BF%A1%E7%94%A8%E9%A3%8E%E9%99%A9%E7%AE%A1%E7%90%86/</url>
    <content><![CDATA[<p><strong>信用风险管理笔记</strong></p>
<h2 id="信用决定"><a href="#信用决定" class="headerlink" title="信用决定"></a>信用决定</h2><p>the probability of Default(PD)，the loss given default(LGD)，the exposure at default(EAD)<br>the overall expected loss(EL)<br>expected loss(EL) = PD <em> LGD </em> EL<br>Time horizon：时间窗口</p>
<p>交易风险：</p>
<ul>
<li>settlement risk 交割风险</li>
<li>financial obligation </li>
</ul>
<p>分析方法：</p>
<ul>
<li>定性分析：sovereign risk ratings</li>
<li>定量分析：historical nature of the data</li>
</ul>
<a id="more"></a>
<h2 id="信用分析"><a href="#信用分析" class="headerlink" title="信用分析"></a>信用分析</h2><h2 id="信用风险的分类和主要概念"><a href="#信用风险的分类和主要概念" class="headerlink" title="信用风险的分类和主要概念"></a>信用风险的分类和主要概念</h2><h2 id="评估方法"><a href="#评估方法" class="headerlink" title="评估方法"></a>评估方法</h2><h2 id="信用风险和信用衍生品"><a href="#信用风险和信用衍生品" class="headerlink" title="信用风险和信用衍生品"></a>信用风险和信用衍生品</h2><h2 id="结构信用风险"><a href="#结构信用风险" class="headerlink" title="结构信用风险"></a>结构信用风险</h2><h2 id="对手方风险"><a href="#对手方风险" class="headerlink" title="对手方风险"></a>对手方风险</h2><h2 id><a href="#" class="headerlink" title=" "></a> </h2>]]></content>
      <categories>
        <category>FRM二级</category>
      </categories>
      <tags>
        <tag>FRM</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2020/03/01/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<a id="more"></a>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
      <categories>
        <category>Hello World</category>
      </categories>
      <tags>
        <tag>hello</tag>
      </tags>
  </entry>
</search>
